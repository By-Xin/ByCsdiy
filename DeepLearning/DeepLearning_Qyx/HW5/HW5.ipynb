{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a1368f0",
   "metadata": {},
   "source": [
    "# 作业5：RNN 生成模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997082ed",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "以 `data/names.txt` 中的英文名作为训练集，利用 RNN 或 LSTM 等方法对字母序列数据进行建模，然后使用拟合的模型随机生成20个名字。本次作业为开放式，不指定各类超参数（如网络结构、学习率、迭代次数等），但需提供必要的输出和诊断结果支持你的选择（如模型是否收敛、效果评价等）。\n",
    "\n",
    "提示：可以参照 `lec12-rnn-generation.zip` 中的代码，但注意英文名不需要像中文那样构建字典，因为可以直接使用26个字母作为字典。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 处理数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T11:42:04.645497700Z",
     "start_time": "2023-12-04T11:42:00.191807700Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import itertools\n",
    "import collections\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T11:42:08.783637Z",
     "start_time": "2023-12-04T11:42:08.623557100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abbas', 'abbey', 'abbott', 'abdi', 'abel']\n"
     ]
    }
   ],
   "source": [
    "# load txt file\n",
    "\n",
    "def read_txt_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        content = file.read().split()\n",
    "        return content\n",
    "\n",
    "dat = read_txt_file('data/names.txt')\n",
    "print(dat[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T11:42:23.907980700Z",
     "start_time": "2023-12-04T11:42:23.892846700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '<EOS>']\n"
     ]
    }
   ],
   "source": [
    "# construct dictionary\n",
    "charset_size = 27 # 26 letters  + 1 <EOS>\n",
    "dictionary = list('abcdefghijklmnopqrstuvwxyz') + ['<EOS>'] \n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T11:42:26.701001Z",
     "start_time": "2023-12-04T11:42:26.639429500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]),\n",
       " array([4, 6]),\n",
       " tensor([[ 4,  0],\n",
       "         [14,  2],\n",
       "         [13,  7],\n",
       "         [26,  4],\n",
       "         [26, 11],\n",
       "         [26, 26]]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# names to tensor\n",
    "\n",
    "\n",
    "def char2tensor(char):\n",
    "    \"\"\"将单个字符转换为 one-hot 编码的张量\"\"\"\n",
    "    tensor = torch.zeros(1, charset_size) # 相当于一个列向量，长度为charset_size，相当于是对于每个字符对应的one-hot编码向量\n",
    "    tensor[0, char2index(char)] = 1 # 初始化全员为0，在index位置为1\n",
    "    return tensor\n",
    "\n",
    "def name2tensor(name):\n",
    "    \"\"\"将名字转换为 one-hot 编码的张量\"\"\"\n",
    "    tensor = torch.zeros(len(name), 1, charset_size) #一个tensor（其实是2d矩阵的感觉），第一个维度是名字的长度（名字中的各个字符），第二个维度是1，第三个维度是每个字符的onehot\n",
    "    for i, char in enumerate(name): #enmuerate\n",
    "        tensor[i, 0, char2index(char)] = 1\n",
    "    return tensor\n",
    "\n",
    "def char2index(char):\n",
    "    \"\"\"Transform a character to its index in the dictionary\n",
    "    Args:\n",
    "        char (str): a character\n",
    "        \n",
    "    Returns:\n",
    "       int: the index of the character in the dictionary\n",
    "        \n",
    "    \"\"\"\n",
    "    return dictionary.index(char.lower()) \n",
    "\n",
    "def names2tensor(NameList):\n",
    "    \"\"\"Transform a list of names to one-hot tensor\n",
    "    Args:\n",
    "        NameList (array): a list of names\n",
    "        \n",
    "    Returns:\n",
    "        tensor: a tensor of shape (LongestNameLength, NumberOfNames, charset_size=27), storing the one-hot representation of names\n",
    "        array: a numpy array of shape (NumberOfNames), storing each name's length\n",
    "        target: a tensor of shape (LongestNameLength, NumberOfNames), storing the index of the next letter\n",
    "        \n",
    "    \"\"\"\n",
    "    names_num = len(NameList) # number of names\n",
    "    names_lens = [len(name) for name in NameList] # a list storing each name's length\n",
    "    max_name_len = max(names_lens) # the longest name's length\n",
    "    \n",
    "    tensor = torch.zeros(max_name_len, names_num, charset_size) # (each char in a name, each name, one-hot vector)\n",
    "    target = torch.zeros(max_name_len, names_num, dtype=int) + charset_size - 1 # initialize with <EOS>\n",
    "    \n",
    "    for name_i in range(names_num): # for each name(idx) in data set\n",
    "        name = NameList[name_i] # get the name\n",
    "        for char_i in range(names_lens[name_i]): # for each char(idx) in the name\n",
    "            # set tensor\n",
    "            tensor[char_i, name_i, char2index(name[char_i])] = 1 # set the corresponding one-hot vector\n",
    "            # set target\n",
    "            if char_i < names_lens[name_i] - 1: # if not the last char (here note that python index starts from 0)\n",
    "                target[char_i, name_i] = char2index(name[char_i + 1]) # target for name_i, char_i is char_i+1\n",
    "                \n",
    "    return tensor, np.array(names_lens), target\n",
    "\n",
    "# test names2tensor\n",
    "names2tensor([\"leon\",\"rachel\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 构建LSTM模型类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![](https://michael-1313341240.cos.ap-shanghai.myqcloud.com/202312042025464.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters Definition:\n",
    "\n",
    "- Suppose there are $h$ hidden units, batch size is $n$, number of inputs is $d$. Thus, $X_t \\in \\mathbb{R}^{n\\times h}, H_t = \\mathbb{R}^{n\\times h}.$\n",
    "- Define Gates (at time $t$):\n",
    "    - Input gate ($I_t \\in \\mathbb{R}^{n\\times h}$) : $I_t = \\text{sigmoid}(X_t W_{xi} + H_{t-1} W_{hi} + b_i)$\n",
    "    - Forget gate ($F_t \\in \\mathbb{R}^{n\\times h}$) : $F_t = \\text{sigmoid}({X_t W_{xf} + H_{t-1} W_{hf} + b_f)}$\n",
    "    - Output gate ($O_t \\in  \\mathbb{R}^{n\\times h}$) : $O_t = \\text{sigmoid}{X_t W_{xo} + H_{t-1} W_{ho} + b_o)}$\n",
    "  \n",
    "  where $W_{x,\\cdot} \\in \\mathbb{R}^{d\\times h}$, $W_{h,\\cdot} \\in \\mathbb{R}^{h\\times h}$, $b_{\\cdot} \\in \\mathbb{R}^{1\\times h}$.\n",
    "\n",
    "- Define Candidate Memory Cell $\\tilde C$:\n",
    "\n",
    "$$\n",
    "  \\tilde C_t = \\text{tanh}(X_t W_{xc} + H_{t-1} W_{hc} + b_c)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "> *Reference*\n",
    ">\n",
    "> *1. Dive Into Deep Learning (https://zh.d2l.ai/chapter_recurrent-modern/lstm.html)*\n",
    ">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LSTM\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(LSTM,self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size #?\n",
    "        \n",
    "        self.X2F = nn.Linear(in_features = input_size + hidden_size,\n",
    "                            out_features = hidden_size )\n",
    "        self.X2I = nn.Linear(in_features = input_size + hidden_size,\n",
    "                            out_features = hidden_size )\n",
    "        self.X2O = nn.Linear(in_features = input_size + hidden_size,\n",
    "                            out_features = hidden_size )\n",
    "        \n",
    "        self.X2Ct = nn.Linear(in_features = input_size + hidden_size,\n",
    "                            out_features = hidden_size )\n",
    "        \n",
    "        self.O2O = nn.Linear(in_features = hidden_size,\n",
    "                            out_features = hidden_size)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, input, hidden, MemCell):\n",
    "        \n",
    "        input_combined = torch.cat((input,hidden),1)     #? how\n",
    "        \n",
    "        ForgetGate = torch.sigmoid(self.X2F(input_combined))   \n",
    "        InputGate = torch.sigmoid(self.X2I(input_combined))\n",
    "        OutputGate = torch.sigmoid(self.X2O(input_combined))\n",
    "        \n",
    "        CandidateMemCell = torch.tanh(self.X2Ct(input_combined))\n",
    "        \n",
    "        MemCell = ForgetGate * MemCell + InputGate * CandidateMemCell\n",
    "        \n",
    "        hidden = OutputGate * torch.tanh(MemCell)\n",
    "        # print(f\"hidden:{hidden.shape}\")\n",
    "        \n",
    "        output = self.O2O(hidden)\n",
    "        output = self.dropout(output)\n",
    "        output = self.logsoftmax(output)\n",
    "        \n",
    "        return output, hidden, MemCell\n",
    "    \n",
    "    def init_hidden(self, batch_size, device):\n",
    "        return torch.zeros((batch_size, self.hidden_size), device = device)\n",
    "\n",
    "    def init_MemCell(self, batch_size, device):\n",
    "        return torch.zeros((batch_size, self.hidden_size), device = device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Test Demo*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "n_hidden = 64\n",
    "lstm = LSTM(charset_size, n_hidden)\n",
    "\n",
    "\n",
    "input = name2tensor(\"leon\").to(device=device)\n",
    "#print(input)\n",
    "hidden = lstm.init_hidden(batch_size=1, device=device)\n",
    "MemCell = lstm.init_MemCell(batch_size=1, device=device)\n",
    "\n",
    "print(input[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\xinby\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\xinby\\AppData\\Local\\Temp\\ipykernel_23456\\317194724.py\", line 1, in <module>\n",
      "    output, next_hidden, next_MemCell  = lstm(input[0], hidden, MemCell)\n",
      "                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\xinby\\.conda\\envs\\win_DL_Q\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\xinby\\AppData\\Local\\Temp\\ipykernel_23456\\1311262696.py\", line 28, in forward\n",
      "    ForgetGate = torch.sigmoid(self.X2F(input_combined))\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\xinby\\.conda\\envs\\win_DL_Q\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\xinby\\.conda\\envs\\win_DL_Q\\Lib\\site-packages\\torch\\nn\\modules\\linear.py\", line 114, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\xinby\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 2105, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\xinby\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\ultratb.py\", line 1396, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\xinby\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\ultratb.py\", line 1287, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\xinby\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\ultratb.py\", line 1140, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\xinby\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\ultratb.py\", line 1055, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\xinby\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\ultratb.py\", line 955, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\xinby\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\ultratb.py\", line 778, in lines\n",
      "    return self._sd.lines\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\xinby\\AppData\\Roaming\\Python\\Python311\\site-packages\\stack_data\\utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\xinby\\AppData\\Roaming\\Python\\Python311\\site-packages\\stack_data\\core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\xinby\\AppData\\Roaming\\Python\\Python311\\site-packages\\stack_data\\utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\xinby\\AppData\\Roaming\\Python\\Python311\\site-packages\\stack_data\\core.py\", line 677, in included_pieces\n",
      "    scope_pieces = self.scope_pieces\n",
      "                   ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\xinby\\AppData\\Roaming\\Python\\Python311\\site-packages\\stack_data\\utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\xinby\\AppData\\Roaming\\Python\\Python311\\site-packages\\stack_data\\core.py\", line 614, in scope_pieces\n",
      "    scope_start, scope_end = self.source.line_range(self.scope)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\xinby\\AppData\\Roaming\\Python\\Python311\\site-packages\\stack_data\\core.py\", line 178, in line_range\n",
      "    return line_range(self.asttext(), node)\n",
      "                      ^^^^^^^^^^^^\n",
      "AttributeError: 'Source' object has no attribute 'asttext'\n"
     ]
    }
   ],
   "source": [
    "output, next_hidden, next_MemCell  = lstm(input[0], hidden, MemCell)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Train LSTM***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed \n",
    "np.random.seed(123)\n",
    "torch.random.manual_seed(123)\n",
    "\n",
    "# set device\n",
    "device = torch.device(\"cuda\") \n",
    "\n",
    "# set hyper-params\n",
    "train = dat\n",
    "train_size = len(train)\n",
    "n_hidden = 512\n",
    "n_epoch = 1009\n",
    "batch_size = 512\n",
    "learning_rate = 0.0005\n",
    "\n",
    "# create LSTM\n",
    "\n",
    "## Initialization\n",
    "lstm = LSTM(input_size = charset_size, hidden_size = n_hidden) # create lstm\n",
    "lstm = lstm.to(device=device) # set gpu/cpu\n",
    "\n",
    "## Optimization\n",
    "opt = torch.optim.Adam(lstm.parameters(), lr=learning_rate)\n",
    "\n",
    "## Loss Function\n",
    "lossfn = nn.NLLLoss(reduction='none') # ? reduction='none'\n",
    "losses = []\n",
    "\n",
    "## Training Structure\n",
    "\n",
    "train_ind = np.arange(train_size) # train_ind for mini-batch shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0/1009,loss = 6.150541305541992\n",
      "epoch1/1009,loss = 5.7172088623046875\n",
      "epoch2/1009,loss = 4.679393291473389\n",
      "epoch3/1009,loss = 4.283895492553711\n",
      "epoch4/1009,loss = 3.999882936477661\n",
      "epoch5/1009,loss = 3.9961092472076416\n",
      "epoch6/1009,loss = 3.843662977218628\n",
      "epoch7/1009,loss = 3.8211402893066406\n",
      "epoch8/1009,loss = 3.75710391998291\n",
      "epoch9/1009,loss = 3.6153817176818848\n",
      "epoch10/1009,loss = 3.6408262252807617\n",
      "epoch11/1009,loss = 3.535834550857544\n",
      "epoch12/1009,loss = 3.5425987243652344\n",
      "epoch13/1009,loss = 3.452939748764038\n",
      "epoch14/1009,loss = 3.444027900695801\n",
      "epoch15/1009,loss = 3.4908132553100586\n",
      "epoch16/1009,loss = 3.5139801502227783\n",
      "epoch17/1009,loss = 3.4338104724884033\n",
      "epoch18/1009,loss = 3.470477819442749\n",
      "epoch19/1009,loss = 3.3385212421417236\n",
      "epoch20/1009,loss = 3.313717842102051\n",
      "epoch21/1009,loss = 3.2628462314605713\n",
      "epoch22/1009,loss = 3.2800190448760986\n",
      "epoch23/1009,loss = 3.292675495147705\n",
      "epoch24/1009,loss = 3.3116378784179688\n",
      "epoch25/1009,loss = 3.3153867721557617\n",
      "epoch26/1009,loss = 3.216372489929199\n",
      "epoch27/1009,loss = 3.234332799911499\n",
      "epoch28/1009,loss = 3.180638074874878\n",
      "epoch29/1009,loss = 3.251558780670166\n",
      "epoch30/1009,loss = 3.1606905460357666\n",
      "epoch31/1009,loss = 3.2364068031311035\n",
      "epoch32/1009,loss = 3.1533384323120117\n",
      "epoch33/1009,loss = 3.1132895946502686\n",
      "epoch34/1009,loss = 3.1482417583465576\n",
      "epoch35/1009,loss = 3.215423822402954\n",
      "epoch36/1009,loss = 3.058483362197876\n",
      "epoch37/1009,loss = 3.1515445709228516\n",
      "epoch38/1009,loss = 3.08023738861084\n",
      "epoch39/1009,loss = 3.062908887863159\n",
      "epoch40/1009,loss = 3.118577003479004\n",
      "epoch41/1009,loss = 2.9673426151275635\n",
      "epoch42/1009,loss = 3.010293960571289\n",
      "epoch43/1009,loss = 2.9744985103607178\n",
      "epoch44/1009,loss = 2.964564800262451\n",
      "epoch45/1009,loss = 2.900745153427124\n",
      "epoch46/1009,loss = 2.9423820972442627\n",
      "epoch47/1009,loss = 2.973341941833496\n",
      "epoch48/1009,loss = 2.9107742309570312\n",
      "epoch49/1009,loss = 2.924363613128662\n",
      "epoch50/1009,loss = 2.8860740661621094\n",
      "epoch51/1009,loss = 2.9129152297973633\n",
      "epoch52/1009,loss = 2.993408203125\n",
      "epoch53/1009,loss = 2.834357261657715\n",
      "epoch54/1009,loss = 2.804119348526001\n",
      "epoch55/1009,loss = 2.7998197078704834\n",
      "epoch56/1009,loss = 2.7212443351745605\n",
      "epoch57/1009,loss = 2.8179030418395996\n",
      "epoch58/1009,loss = 2.7239291667938232\n",
      "epoch59/1009,loss = 2.7360644340515137\n",
      "epoch60/1009,loss = 2.756798028945923\n",
      "epoch61/1009,loss = 2.755124568939209\n",
      "epoch62/1009,loss = 2.7141900062561035\n",
      "epoch63/1009,loss = 2.6242008209228516\n",
      "epoch64/1009,loss = 2.7679154872894287\n",
      "epoch65/1009,loss = 2.7174060344696045\n",
      "epoch66/1009,loss = 2.8294830322265625\n",
      "epoch67/1009,loss = 2.673962354660034\n",
      "epoch68/1009,loss = 2.6494648456573486\n",
      "epoch69/1009,loss = 2.6161468029022217\n",
      "epoch70/1009,loss = 2.713923692703247\n",
      "epoch71/1009,loss = 2.6603007316589355\n",
      "epoch72/1009,loss = 2.749124526977539\n",
      "epoch73/1009,loss = 2.676084041595459\n",
      "epoch74/1009,loss = 2.774637460708618\n",
      "epoch75/1009,loss = 2.658389091491699\n",
      "epoch76/1009,loss = 2.68342924118042\n",
      "epoch77/1009,loss = 2.6241261959075928\n",
      "epoch78/1009,loss = 2.6352922916412354\n",
      "epoch79/1009,loss = 2.625269651412964\n",
      "epoch80/1009,loss = 2.722611427307129\n",
      "epoch81/1009,loss = 2.635648250579834\n",
      "epoch82/1009,loss = 2.5912024974823\n",
      "epoch83/1009,loss = 2.520479679107666\n",
      "epoch84/1009,loss = 2.5878093242645264\n",
      "epoch85/1009,loss = 2.6159377098083496\n",
      "epoch86/1009,loss = 2.5553395748138428\n",
      "epoch87/1009,loss = 2.6598691940307617\n",
      "epoch88/1009,loss = 2.628032922744751\n",
      "epoch89/1009,loss = 2.585437059402466\n",
      "epoch90/1009,loss = 2.5933620929718018\n",
      "epoch91/1009,loss = 2.635222911834717\n",
      "epoch92/1009,loss = 2.5987677574157715\n",
      "epoch93/1009,loss = 2.4852828979492188\n",
      "epoch94/1009,loss = 2.5849051475524902\n",
      "epoch95/1009,loss = 2.6352739334106445\n",
      "epoch96/1009,loss = 2.5114779472351074\n",
      "epoch97/1009,loss = 2.4123775959014893\n",
      "epoch98/1009,loss = 2.4675939083099365\n",
      "epoch99/1009,loss = 2.635305881500244\n",
      "epoch100/1009,loss = 2.655121088027954\n",
      "epoch101/1009,loss = 2.5836379528045654\n",
      "epoch102/1009,loss = 2.5022575855255127\n",
      "epoch103/1009,loss = 2.4244534969329834\n",
      "epoch104/1009,loss = 2.510016679763794\n",
      "epoch105/1009,loss = 2.4498777389526367\n",
      "epoch106/1009,loss = 2.6330177783966064\n",
      "epoch107/1009,loss = 2.4735751152038574\n",
      "epoch108/1009,loss = 2.470243215560913\n",
      "epoch109/1009,loss = 2.5576233863830566\n",
      "epoch110/1009,loss = 2.5836808681488037\n",
      "epoch111/1009,loss = 2.5003716945648193\n",
      "epoch112/1009,loss = 2.456819772720337\n",
      "epoch113/1009,loss = 2.5575613975524902\n",
      "epoch114/1009,loss = 2.3981640338897705\n",
      "epoch115/1009,loss = 2.442655086517334\n",
      "epoch116/1009,loss = 2.4380686283111572\n",
      "epoch117/1009,loss = 2.493241548538208\n",
      "epoch118/1009,loss = 2.51900053024292\n",
      "epoch119/1009,loss = 2.423095703125\n",
      "epoch120/1009,loss = 2.5908203125\n",
      "epoch121/1009,loss = 2.4965386390686035\n",
      "epoch122/1009,loss = 2.522010564804077\n",
      "epoch123/1009,loss = 2.4648520946502686\n",
      "epoch124/1009,loss = 2.437027931213379\n",
      "epoch125/1009,loss = 2.5785319805145264\n",
      "epoch126/1009,loss = 2.4996180534362793\n",
      "epoch127/1009,loss = 2.538205623626709\n",
      "epoch128/1009,loss = 2.429609537124634\n",
      "epoch129/1009,loss = 2.6071598529815674\n",
      "epoch130/1009,loss = 2.3273510932922363\n",
      "epoch131/1009,loss = 2.458156108856201\n",
      "epoch132/1009,loss = 2.4302175045013428\n",
      "epoch133/1009,loss = 2.4076642990112305\n",
      "epoch134/1009,loss = 2.3729991912841797\n",
      "epoch135/1009,loss = 2.372286796569824\n",
      "epoch136/1009,loss = 2.4768712520599365\n",
      "epoch137/1009,loss = 2.4213080406188965\n",
      "epoch138/1009,loss = 2.3728370666503906\n",
      "epoch139/1009,loss = 2.3837502002716064\n",
      "epoch140/1009,loss = 2.435384750366211\n",
      "epoch141/1009,loss = 2.434316396713257\n",
      "epoch142/1009,loss = 2.402731418609619\n",
      "epoch143/1009,loss = 2.4500973224639893\n",
      "epoch144/1009,loss = 2.527869939804077\n",
      "epoch145/1009,loss = 2.4682059288024902\n",
      "epoch146/1009,loss = 2.4164528846740723\n",
      "epoch147/1009,loss = 2.455598831176758\n",
      "epoch148/1009,loss = 2.460153341293335\n",
      "epoch149/1009,loss = 2.5676350593566895\n",
      "epoch150/1009,loss = 2.4167063236236572\n",
      "epoch151/1009,loss = 2.328425884246826\n",
      "epoch152/1009,loss = 2.4156975746154785\n",
      "epoch153/1009,loss = 2.411548614501953\n",
      "epoch154/1009,loss = 2.406148672103882\n",
      "epoch155/1009,loss = 2.513094902038574\n",
      "epoch156/1009,loss = 2.474959135055542\n",
      "epoch157/1009,loss = 2.3744490146636963\n",
      "epoch158/1009,loss = 2.3778204917907715\n",
      "epoch159/1009,loss = 2.3507676124572754\n",
      "epoch160/1009,loss = 2.3733668327331543\n",
      "epoch161/1009,loss = 2.3781981468200684\n",
      "epoch162/1009,loss = 2.4855940341949463\n",
      "epoch163/1009,loss = 2.399273633956909\n",
      "epoch164/1009,loss = 2.424245595932007\n",
      "epoch165/1009,loss = 2.2922964096069336\n",
      "epoch166/1009,loss = 2.3925161361694336\n",
      "epoch167/1009,loss = 2.371133327484131\n",
      "epoch168/1009,loss = 2.2998528480529785\n",
      "epoch169/1009,loss = 2.286895275115967\n",
      "epoch170/1009,loss = 2.3558409214019775\n",
      "epoch171/1009,loss = 2.455526113510132\n",
      "epoch172/1009,loss = 2.3707616329193115\n",
      "epoch173/1009,loss = 2.287978172302246\n",
      "epoch174/1009,loss = 2.332031726837158\n",
      "epoch175/1009,loss = 2.3179187774658203\n",
      "epoch176/1009,loss = 2.2922005653381348\n",
      "epoch177/1009,loss = 2.346982717514038\n",
      "epoch178/1009,loss = 2.35345458984375\n",
      "epoch179/1009,loss = 2.2577900886535645\n",
      "epoch180/1009,loss = 2.4808261394500732\n",
      "epoch181/1009,loss = 2.3635244369506836\n",
      "epoch182/1009,loss = 2.517900228500366\n",
      "epoch183/1009,loss = 2.3220882415771484\n",
      "epoch184/1009,loss = 2.4242067337036133\n",
      "epoch185/1009,loss = 2.343905448913574\n",
      "epoch186/1009,loss = 2.415241241455078\n",
      "epoch187/1009,loss = 2.3381974697113037\n",
      "epoch188/1009,loss = 2.230556011199951\n",
      "epoch189/1009,loss = 2.4181454181671143\n",
      "epoch190/1009,loss = 2.3143510818481445\n",
      "epoch191/1009,loss = 2.349957227706909\n",
      "epoch192/1009,loss = 2.405200719833374\n",
      "epoch193/1009,loss = 2.4036736488342285\n",
      "epoch194/1009,loss = 2.4541642665863037\n",
      "epoch195/1009,loss = 2.4741499423980713\n",
      "epoch196/1009,loss = 2.315042018890381\n",
      "epoch197/1009,loss = 2.249086856842041\n",
      "epoch198/1009,loss = 2.3818931579589844\n",
      "epoch199/1009,loss = 2.3016748428344727\n",
      "epoch200/1009,loss = 2.3702266216278076\n",
      "epoch201/1009,loss = 2.298750638961792\n",
      "epoch202/1009,loss = 2.2802658081054688\n",
      "epoch203/1009,loss = 2.240137815475464\n",
      "epoch204/1009,loss = 2.413679838180542\n",
      "epoch205/1009,loss = 2.230579137802124\n",
      "epoch206/1009,loss = 2.362394332885742\n",
      "epoch207/1009,loss = 2.2847867012023926\n",
      "epoch208/1009,loss = 2.2588911056518555\n",
      "epoch209/1009,loss = 2.241945743560791\n",
      "epoch210/1009,loss = 2.360466957092285\n",
      "epoch211/1009,loss = 2.3403384685516357\n",
      "epoch212/1009,loss = 2.236124038696289\n",
      "epoch213/1009,loss = 2.216341018676758\n",
      "epoch214/1009,loss = 2.3778650760650635\n",
      "epoch215/1009,loss = 2.217629909515381\n",
      "epoch216/1009,loss = 2.2667160034179688\n",
      "epoch217/1009,loss = 2.2503952980041504\n",
      "epoch218/1009,loss = 2.271078586578369\n",
      "epoch219/1009,loss = 2.2961997985839844\n",
      "epoch220/1009,loss = 2.2061543464660645\n",
      "epoch221/1009,loss = 2.219672203063965\n",
      "epoch222/1009,loss = 2.291903495788574\n",
      "epoch223/1009,loss = 2.253286600112915\n",
      "epoch224/1009,loss = 2.2313740253448486\n",
      "epoch225/1009,loss = 2.433171033859253\n",
      "epoch226/1009,loss = 2.357032537460327\n",
      "epoch227/1009,loss = 2.2775251865386963\n",
      "epoch228/1009,loss = 2.3863017559051514\n",
      "epoch229/1009,loss = 2.1739768981933594\n",
      "epoch230/1009,loss = 2.2435100078582764\n",
      "epoch231/1009,loss = 2.4340410232543945\n",
      "epoch232/1009,loss = 2.349896192550659\n",
      "epoch233/1009,loss = 2.196260452270508\n",
      "epoch234/1009,loss = 2.251542329788208\n",
      "epoch235/1009,loss = 2.186872720718384\n",
      "epoch236/1009,loss = 2.2712364196777344\n",
      "epoch237/1009,loss = 2.2377283573150635\n",
      "epoch238/1009,loss = 2.300382375717163\n",
      "epoch239/1009,loss = 2.198835611343384\n",
      "epoch240/1009,loss = 2.3001208305358887\n",
      "epoch241/1009,loss = 2.332489013671875\n",
      "epoch242/1009,loss = 2.2347426414489746\n",
      "epoch243/1009,loss = 2.351170778274536\n",
      "epoch244/1009,loss = 2.2952258586883545\n",
      "epoch245/1009,loss = 2.225809335708618\n",
      "epoch246/1009,loss = 2.3740570545196533\n",
      "epoch247/1009,loss = 2.1611125469207764\n",
      "epoch248/1009,loss = 2.187857151031494\n",
      "epoch249/1009,loss = 2.109506368637085\n",
      "epoch250/1009,loss = 2.289665460586548\n",
      "epoch251/1009,loss = 2.3251140117645264\n",
      "epoch252/1009,loss = 2.2655463218688965\n",
      "epoch253/1009,loss = 2.1994996070861816\n",
      "epoch254/1009,loss = 2.2569239139556885\n",
      "epoch255/1009,loss = 2.2472736835479736\n",
      "epoch256/1009,loss = 2.291569948196411\n",
      "epoch257/1009,loss = 2.223809242248535\n",
      "epoch258/1009,loss = 2.218111753463745\n",
      "epoch259/1009,loss = 2.216809034347534\n",
      "epoch260/1009,loss = 2.2459018230438232\n",
      "epoch261/1009,loss = 2.176614999771118\n",
      "epoch262/1009,loss = 2.3141329288482666\n",
      "epoch263/1009,loss = 2.316516637802124\n",
      "epoch264/1009,loss = 2.3608570098876953\n",
      "epoch265/1009,loss = 2.220838785171509\n",
      "epoch266/1009,loss = 2.160299301147461\n",
      "epoch267/1009,loss = 2.1529762744903564\n",
      "epoch268/1009,loss = 2.279832601547241\n",
      "epoch269/1009,loss = 2.2728002071380615\n",
      "epoch270/1009,loss = 2.17388916015625\n",
      "epoch271/1009,loss = 2.2060792446136475\n",
      "epoch272/1009,loss = 2.262577772140503\n",
      "epoch273/1009,loss = 2.1865415573120117\n",
      "epoch274/1009,loss = 2.238908052444458\n",
      "epoch275/1009,loss = 2.2837159633636475\n",
      "epoch276/1009,loss = 2.186129570007324\n",
      "epoch277/1009,loss = 2.2108869552612305\n",
      "epoch278/1009,loss = 2.324035882949829\n",
      "epoch279/1009,loss = 2.137681722640991\n",
      "epoch280/1009,loss = 2.1948819160461426\n",
      "epoch281/1009,loss = 2.277026653289795\n",
      "epoch282/1009,loss = 2.149144411087036\n",
      "epoch283/1009,loss = 2.1392345428466797\n",
      "epoch284/1009,loss = 2.0713558197021484\n",
      "epoch285/1009,loss = 2.2107412815093994\n",
      "epoch286/1009,loss = 2.2186689376831055\n",
      "epoch287/1009,loss = 2.1330926418304443\n",
      "epoch288/1009,loss = 2.303067684173584\n",
      "epoch289/1009,loss = 2.256686210632324\n",
      "epoch290/1009,loss = 2.292506217956543\n",
      "epoch291/1009,loss = 2.34297513961792\n",
      "epoch292/1009,loss = 2.203946113586426\n",
      "epoch293/1009,loss = 2.1369705200195312\n",
      "epoch294/1009,loss = 2.214712142944336\n",
      "epoch295/1009,loss = 2.264843225479126\n",
      "epoch296/1009,loss = 2.3976993560791016\n",
      "epoch297/1009,loss = 2.2333104610443115\n",
      "epoch298/1009,loss = 2.0924646854400635\n",
      "epoch299/1009,loss = 2.3824970722198486\n",
      "epoch300/1009,loss = 2.167670488357544\n",
      "epoch301/1009,loss = 2.312398910522461\n",
      "epoch302/1009,loss = 2.154062509536743\n",
      "epoch303/1009,loss = 2.2785940170288086\n",
      "epoch304/1009,loss = 2.25924015045166\n",
      "epoch305/1009,loss = 2.1904499530792236\n",
      "epoch306/1009,loss = 2.2020671367645264\n",
      "epoch307/1009,loss = 2.2341887950897217\n",
      "epoch308/1009,loss = 2.188509464263916\n",
      "epoch309/1009,loss = 2.177438497543335\n",
      "epoch310/1009,loss = 2.1744160652160645\n",
      "epoch311/1009,loss = 2.0899806022644043\n",
      "epoch312/1009,loss = 2.194136619567871\n",
      "epoch313/1009,loss = 2.163283109664917\n",
      "epoch314/1009,loss = 2.2639994621276855\n",
      "epoch315/1009,loss = 2.2030763626098633\n",
      "epoch316/1009,loss = 2.1818184852600098\n",
      "epoch317/1009,loss = 2.247861623764038\n",
      "epoch318/1009,loss = 2.118312358856201\n",
      "epoch319/1009,loss = 2.2062385082244873\n",
      "epoch320/1009,loss = 2.0940699577331543\n",
      "epoch321/1009,loss = 2.146054267883301\n",
      "epoch322/1009,loss = 2.0951833724975586\n",
      "epoch323/1009,loss = 2.251322031021118\n",
      "epoch324/1009,loss = 2.229903221130371\n",
      "epoch325/1009,loss = 2.146744728088379\n",
      "epoch326/1009,loss = 2.156440019607544\n",
      "epoch327/1009,loss = 2.166285753250122\n",
      "epoch328/1009,loss = 2.215860366821289\n",
      "epoch329/1009,loss = 2.2493643760681152\n",
      "epoch330/1009,loss = 2.0717196464538574\n",
      "epoch331/1009,loss = 2.1243016719818115\n",
      "epoch332/1009,loss = 2.1625590324401855\n",
      "epoch333/1009,loss = 2.3152832984924316\n",
      "epoch334/1009,loss = 2.1125054359436035\n",
      "epoch335/1009,loss = 2.261650323867798\n",
      "epoch336/1009,loss = 2.0785040855407715\n",
      "epoch337/1009,loss = 2.0694973468780518\n",
      "epoch338/1009,loss = 2.208672046661377\n",
      "epoch339/1009,loss = 2.2371954917907715\n",
      "epoch340/1009,loss = 2.139061689376831\n",
      "epoch341/1009,loss = 2.1570322513580322\n",
      "epoch342/1009,loss = 2.1544270515441895\n",
      "epoch343/1009,loss = 2.301840305328369\n",
      "epoch344/1009,loss = 2.172435760498047\n",
      "epoch345/1009,loss = 2.1819798946380615\n",
      "epoch346/1009,loss = 2.036707639694214\n",
      "epoch347/1009,loss = 2.1538844108581543\n",
      "epoch348/1009,loss = 2.2241697311401367\n",
      "epoch349/1009,loss = 2.1898579597473145\n",
      "epoch350/1009,loss = 2.130387783050537\n",
      "epoch351/1009,loss = 2.1659626960754395\n",
      "epoch352/1009,loss = 2.110656261444092\n",
      "epoch353/1009,loss = 2.0714712142944336\n",
      "epoch354/1009,loss = 2.1962780952453613\n",
      "epoch355/1009,loss = 1.9819049835205078\n",
      "epoch356/1009,loss = 2.143435478210449\n",
      "epoch357/1009,loss = 2.1672816276550293\n",
      "epoch358/1009,loss = 2.210183620452881\n",
      "epoch359/1009,loss = 2.138087034225464\n",
      "epoch360/1009,loss = 2.0441606044769287\n",
      "epoch361/1009,loss = 2.164389133453369\n",
      "epoch362/1009,loss = 2.2170052528381348\n",
      "epoch363/1009,loss = 2.191256523132324\n",
      "epoch364/1009,loss = 2.115483045578003\n",
      "epoch365/1009,loss = 2.100250482559204\n",
      "epoch366/1009,loss = 2.297260046005249\n",
      "epoch367/1009,loss = 2.165262222290039\n",
      "epoch368/1009,loss = 2.1430461406707764\n",
      "epoch369/1009,loss = 1.963999629020691\n",
      "epoch370/1009,loss = 2.147721290588379\n",
      "epoch371/1009,loss = 2.1916415691375732\n",
      "epoch372/1009,loss = 2.161647319793701\n",
      "epoch373/1009,loss = 2.2358481884002686\n",
      "epoch374/1009,loss = 2.163325786590576\n",
      "epoch375/1009,loss = 2.1125118732452393\n",
      "epoch376/1009,loss = 2.1536500453948975\n",
      "epoch377/1009,loss = 2.109097957611084\n",
      "epoch378/1009,loss = 2.240185260772705\n",
      "epoch379/1009,loss = 2.171621084213257\n",
      "epoch380/1009,loss = 2.2265288829803467\n",
      "epoch381/1009,loss = 2.111889123916626\n",
      "epoch382/1009,loss = 2.0642499923706055\n",
      "epoch383/1009,loss = 2.054990291595459\n",
      "epoch384/1009,loss = 2.1739823818206787\n",
      "epoch385/1009,loss = 2.079864501953125\n",
      "epoch386/1009,loss = 2.1521155834198\n",
      "epoch387/1009,loss = 2.1248795986175537\n",
      "epoch388/1009,loss = 2.153548240661621\n",
      "epoch389/1009,loss = 2.094606876373291\n",
      "epoch390/1009,loss = 2.140130043029785\n",
      "epoch391/1009,loss = 2.118642568588257\n",
      "epoch392/1009,loss = 2.2193849086761475\n",
      "epoch393/1009,loss = 2.176769256591797\n",
      "epoch394/1009,loss = 2.178457260131836\n",
      "epoch395/1009,loss = 2.031329870223999\n",
      "epoch396/1009,loss = 2.070795774459839\n",
      "epoch397/1009,loss = 2.0310192108154297\n",
      "epoch398/1009,loss = 2.0685312747955322\n",
      "epoch399/1009,loss = 1.9518437385559082\n",
      "epoch400/1009,loss = 2.0495412349700928\n",
      "epoch401/1009,loss = 2.047360897064209\n",
      "epoch402/1009,loss = 2.0381827354431152\n",
      "epoch403/1009,loss = 2.277599573135376\n",
      "epoch404/1009,loss = 2.11049222946167\n",
      "epoch405/1009,loss = 2.1234943866729736\n",
      "epoch406/1009,loss = 2.0488669872283936\n",
      "epoch407/1009,loss = 2.0382585525512695\n",
      "epoch408/1009,loss = 2.139801025390625\n",
      "epoch409/1009,loss = 2.089643716812134\n",
      "epoch410/1009,loss = 2.109785795211792\n",
      "epoch411/1009,loss = 2.0880494117736816\n",
      "epoch412/1009,loss = 1.9549933671951294\n",
      "epoch413/1009,loss = 2.0418074131011963\n",
      "epoch414/1009,loss = 2.1073696613311768\n",
      "epoch415/1009,loss = 1.994163990020752\n",
      "epoch416/1009,loss = 2.0673699378967285\n",
      "epoch417/1009,loss = 1.9736119508743286\n",
      "epoch418/1009,loss = 2.0910894870758057\n",
      "epoch419/1009,loss = 1.996371865272522\n",
      "epoch420/1009,loss = 1.9934639930725098\n",
      "epoch421/1009,loss = 2.0395450592041016\n",
      "epoch422/1009,loss = 2.0277881622314453\n",
      "epoch423/1009,loss = 2.014381170272827\n",
      "epoch424/1009,loss = 2.0046775341033936\n",
      "epoch425/1009,loss = 2.085329055786133\n",
      "epoch426/1009,loss = 2.0222816467285156\n",
      "epoch427/1009,loss = 1.984651803970337\n",
      "epoch428/1009,loss = 2.1288094520568848\n",
      "epoch429/1009,loss = 2.1066737174987793\n",
      "epoch430/1009,loss = 2.003657579421997\n",
      "epoch431/1009,loss = 2.019819498062134\n",
      "epoch432/1009,loss = 1.9815263748168945\n",
      "epoch433/1009,loss = 2.05983304977417\n",
      "epoch434/1009,loss = 1.9975205659866333\n",
      "epoch435/1009,loss = 2.1203315258026123\n",
      "epoch436/1009,loss = 2.0938544273376465\n",
      "epoch437/1009,loss = 2.146710157394409\n",
      "epoch438/1009,loss = 2.0685129165649414\n",
      "epoch439/1009,loss = 2.137594699859619\n",
      "epoch440/1009,loss = 2.001660108566284\n",
      "epoch441/1009,loss = 2.0731561183929443\n",
      "epoch442/1009,loss = 2.06974196434021\n",
      "epoch443/1009,loss = 2.0029330253601074\n",
      "epoch444/1009,loss = 1.9442623853683472\n",
      "epoch445/1009,loss = 2.021697521209717\n",
      "epoch446/1009,loss = 2.094167470932007\n",
      "epoch447/1009,loss = 2.0641462802886963\n",
      "epoch448/1009,loss = 2.002763271331787\n",
      "epoch449/1009,loss = 2.054025888442993\n",
      "epoch450/1009,loss = 2.2071964740753174\n",
      "epoch451/1009,loss = 1.9669077396392822\n",
      "epoch452/1009,loss = 2.0109617710113525\n",
      "epoch453/1009,loss = 1.943357229232788\n",
      "epoch454/1009,loss = 2.039139986038208\n",
      "epoch455/1009,loss = 1.9922232627868652\n",
      "epoch456/1009,loss = 2.1602368354797363\n",
      "epoch457/1009,loss = 2.0909407138824463\n",
      "epoch458/1009,loss = 2.004002094268799\n",
      "epoch459/1009,loss = 2.034130573272705\n",
      "epoch460/1009,loss = 2.041937828063965\n",
      "epoch461/1009,loss = 2.1060404777526855\n",
      "epoch462/1009,loss = 2.024958372116089\n",
      "epoch463/1009,loss = 2.063330888748169\n",
      "epoch464/1009,loss = 2.0763638019561768\n",
      "epoch465/1009,loss = 1.9975478649139404\n",
      "epoch466/1009,loss = 2.0371949672698975\n",
      "epoch467/1009,loss = 1.9963680505752563\n",
      "epoch468/1009,loss = 2.0144381523132324\n",
      "epoch469/1009,loss = 2.05562162399292\n",
      "epoch470/1009,loss = 2.0566234588623047\n",
      "epoch471/1009,loss = 2.0752851963043213\n",
      "epoch472/1009,loss = 1.9752291440963745\n",
      "epoch473/1009,loss = 1.908076286315918\n",
      "epoch474/1009,loss = 2.1027677059173584\n",
      "epoch475/1009,loss = 1.9911253452301025\n",
      "epoch476/1009,loss = 2.1373791694641113\n",
      "epoch477/1009,loss = 1.9991858005523682\n",
      "epoch478/1009,loss = 2.0691938400268555\n",
      "epoch479/1009,loss = 1.945900797843933\n",
      "epoch480/1009,loss = 2.08223295211792\n",
      "epoch481/1009,loss = 1.9366953372955322\n",
      "epoch482/1009,loss = 2.0473110675811768\n",
      "epoch483/1009,loss = 1.9548273086547852\n",
      "epoch484/1009,loss = 1.8942981958389282\n",
      "epoch485/1009,loss = 2.1978328227996826\n",
      "epoch486/1009,loss = 2.0098938941955566\n",
      "epoch487/1009,loss = 1.9020392894744873\n",
      "epoch488/1009,loss = 2.0667970180511475\n",
      "epoch489/1009,loss = 1.9322192668914795\n",
      "epoch490/1009,loss = 1.9283965826034546\n",
      "epoch491/1009,loss = 1.9045132398605347\n",
      "epoch492/1009,loss = 1.9822306632995605\n",
      "epoch493/1009,loss = 2.115668296813965\n",
      "epoch494/1009,loss = 2.055875539779663\n",
      "epoch495/1009,loss = 1.8784879446029663\n",
      "epoch496/1009,loss = 1.8744127750396729\n",
      "epoch497/1009,loss = 2.067333936691284\n",
      "epoch498/1009,loss = 1.937086820602417\n",
      "epoch499/1009,loss = 2.0363874435424805\n",
      "epoch500/1009,loss = 2.046337127685547\n",
      "epoch501/1009,loss = 1.9624019861221313\n",
      "epoch502/1009,loss = 2.0278587341308594\n",
      "epoch503/1009,loss = 2.015733480453491\n",
      "epoch504/1009,loss = 1.99965238571167\n",
      "epoch505/1009,loss = 1.8058758974075317\n",
      "epoch506/1009,loss = 1.971081256866455\n",
      "epoch507/1009,loss = 1.9486652612686157\n",
      "epoch508/1009,loss = 2.0473172664642334\n",
      "epoch509/1009,loss = 1.8742605447769165\n",
      "epoch510/1009,loss = 1.9882780313491821\n",
      "epoch511/1009,loss = 2.000972270965576\n",
      "epoch512/1009,loss = 1.947087287902832\n",
      "epoch513/1009,loss = 1.9320063591003418\n",
      "epoch514/1009,loss = 1.9581589698791504\n",
      "epoch515/1009,loss = 1.9229085445404053\n",
      "epoch516/1009,loss = 1.9084877967834473\n",
      "epoch517/1009,loss = 1.8986058235168457\n",
      "epoch518/1009,loss = 1.9918662309646606\n",
      "epoch519/1009,loss = 1.902208685874939\n",
      "epoch520/1009,loss = 1.8973143100738525\n",
      "epoch521/1009,loss = 1.8844276666641235\n",
      "epoch522/1009,loss = 1.9455457925796509\n",
      "epoch523/1009,loss = 2.0237345695495605\n",
      "epoch524/1009,loss = 1.9241905212402344\n",
      "epoch525/1009,loss = 1.8395198583602905\n",
      "epoch526/1009,loss = 1.931178331375122\n",
      "epoch527/1009,loss = 1.995676875114441\n",
      "epoch528/1009,loss = 2.0134456157684326\n",
      "epoch529/1009,loss = 1.9934428930282593\n",
      "epoch530/1009,loss = 1.9342257976531982\n",
      "epoch531/1009,loss = 1.8610323667526245\n",
      "epoch532/1009,loss = 1.875886082649231\n",
      "epoch533/1009,loss = 1.9857456684112549\n",
      "epoch534/1009,loss = 1.949963927268982\n",
      "epoch535/1009,loss = 1.9397095441818237\n",
      "epoch536/1009,loss = 1.8862992525100708\n",
      "epoch537/1009,loss = 1.9463742971420288\n",
      "epoch538/1009,loss = 1.9225114583969116\n",
      "epoch539/1009,loss = 2.0369560718536377\n",
      "epoch540/1009,loss = 1.9452351331710815\n",
      "epoch541/1009,loss = 1.762377381324768\n",
      "epoch542/1009,loss = 1.8660218715667725\n",
      "epoch543/1009,loss = 2.070251703262329\n",
      "epoch544/1009,loss = 2.075563907623291\n",
      "epoch545/1009,loss = 1.8765013217926025\n",
      "epoch546/1009,loss = 1.9930378198623657\n",
      "epoch547/1009,loss = 1.8907631635665894\n",
      "epoch548/1009,loss = 1.938965916633606\n",
      "epoch549/1009,loss = 1.901149868965149\n",
      "epoch550/1009,loss = 1.9426935911178589\n",
      "epoch551/1009,loss = 1.899167776107788\n",
      "epoch552/1009,loss = 1.8985357284545898\n",
      "epoch553/1009,loss = 1.7980159521102905\n",
      "epoch554/1009,loss = 1.9925730228424072\n",
      "epoch555/1009,loss = 1.990676999092102\n",
      "epoch556/1009,loss = 1.9420795440673828\n",
      "epoch557/1009,loss = 1.9578454494476318\n",
      "epoch558/1009,loss = 1.8260393142700195\n",
      "epoch559/1009,loss = 1.9688657522201538\n",
      "epoch560/1009,loss = 1.792148232460022\n",
      "epoch561/1009,loss = 2.0875587463378906\n",
      "epoch562/1009,loss = 1.841416597366333\n",
      "epoch563/1009,loss = 1.9197745323181152\n",
      "epoch564/1009,loss = 1.8975107669830322\n",
      "epoch565/1009,loss = 1.8156629800796509\n",
      "epoch566/1009,loss = 1.9059778451919556\n",
      "epoch567/1009,loss = 2.0575544834136963\n",
      "epoch568/1009,loss = 1.8927745819091797\n",
      "epoch569/1009,loss = 1.798530101776123\n",
      "epoch570/1009,loss = 1.964847445487976\n",
      "epoch571/1009,loss = 1.9387943744659424\n",
      "epoch572/1009,loss = 1.9520196914672852\n",
      "epoch573/1009,loss = 1.7885794639587402\n",
      "epoch574/1009,loss = 1.900330662727356\n",
      "epoch575/1009,loss = 1.8584398031234741\n",
      "epoch576/1009,loss = 1.8842813968658447\n",
      "epoch577/1009,loss = 1.8052784204483032\n",
      "epoch578/1009,loss = 1.971266269683838\n",
      "epoch579/1009,loss = 1.9676856994628906\n",
      "epoch580/1009,loss = 1.8578624725341797\n",
      "epoch581/1009,loss = 1.845103144645691\n",
      "epoch582/1009,loss = 1.8870686292648315\n",
      "epoch583/1009,loss = 1.796554684638977\n",
      "epoch584/1009,loss = 1.8273133039474487\n",
      "epoch585/1009,loss = 1.9149199724197388\n",
      "epoch586/1009,loss = 1.9561301469802856\n",
      "epoch587/1009,loss = 1.8405814170837402\n",
      "epoch588/1009,loss = 1.92081618309021\n",
      "epoch589/1009,loss = 1.9011427164077759\n",
      "epoch590/1009,loss = 1.7199440002441406\n",
      "epoch591/1009,loss = 1.7297453880310059\n",
      "epoch592/1009,loss = 1.8928108215332031\n",
      "epoch593/1009,loss = 1.9227179288864136\n",
      "epoch594/1009,loss = 1.936031460762024\n",
      "epoch595/1009,loss = 1.8704737424850464\n",
      "epoch596/1009,loss = 1.809691309928894\n",
      "epoch597/1009,loss = 1.9066407680511475\n",
      "epoch598/1009,loss = 1.7940771579742432\n",
      "epoch599/1009,loss = 1.7727653980255127\n",
      "epoch600/1009,loss = 1.7776545286178589\n",
      "epoch601/1009,loss = 1.8438233137130737\n",
      "epoch602/1009,loss = 1.8322404623031616\n",
      "epoch603/1009,loss = 1.8074921369552612\n",
      "epoch604/1009,loss = 1.73860764503479\n",
      "epoch605/1009,loss = 1.8948781490325928\n",
      "epoch606/1009,loss = 1.7632684707641602\n",
      "epoch607/1009,loss = 1.7865880727767944\n",
      "epoch608/1009,loss = 1.7360854148864746\n",
      "epoch609/1009,loss = 1.9135912656784058\n",
      "epoch610/1009,loss = 1.6997160911560059\n",
      "epoch611/1009,loss = 1.9033787250518799\n",
      "epoch612/1009,loss = 1.8522745370864868\n",
      "epoch613/1009,loss = 1.8137881755828857\n",
      "epoch614/1009,loss = 1.8385018110275269\n",
      "epoch615/1009,loss = 1.7836066484451294\n",
      "epoch616/1009,loss = 1.824933648109436\n",
      "epoch617/1009,loss = 1.8174721002578735\n",
      "epoch618/1009,loss = 1.7612472772598267\n",
      "epoch619/1009,loss = 1.8905179500579834\n",
      "epoch620/1009,loss = 1.9662065505981445\n",
      "epoch621/1009,loss = 1.8237003087997437\n",
      "epoch622/1009,loss = 1.7455965280532837\n",
      "epoch623/1009,loss = 1.8134123086929321\n",
      "epoch624/1009,loss = 1.9169694185256958\n",
      "epoch625/1009,loss = 1.9230704307556152\n",
      "epoch626/1009,loss = 1.7885489463806152\n",
      "epoch627/1009,loss = 1.8710397481918335\n",
      "epoch628/1009,loss = 1.8159589767456055\n",
      "epoch629/1009,loss = 1.821245789527893\n",
      "epoch630/1009,loss = 1.9255203008651733\n",
      "epoch631/1009,loss = 1.756223440170288\n",
      "epoch632/1009,loss = 1.7525705099105835\n",
      "epoch633/1009,loss = 1.8696386814117432\n",
      "epoch634/1009,loss = 1.8300409317016602\n",
      "epoch635/1009,loss = 1.8205664157867432\n",
      "epoch636/1009,loss = 1.8215336799621582\n",
      "epoch637/1009,loss = 1.8123869895935059\n",
      "epoch638/1009,loss = 1.7247035503387451\n",
      "epoch639/1009,loss = 1.8126124143600464\n",
      "epoch640/1009,loss = 1.6582484245300293\n",
      "epoch641/1009,loss = 1.7998850345611572\n",
      "epoch642/1009,loss = 1.7345350980758667\n",
      "epoch643/1009,loss = 1.88043212890625\n",
      "epoch644/1009,loss = 1.7907609939575195\n",
      "epoch645/1009,loss = 1.6967755556106567\n",
      "epoch646/1009,loss = 1.7318681478500366\n",
      "epoch647/1009,loss = 1.8513604402542114\n",
      "epoch648/1009,loss = 1.8020976781845093\n",
      "epoch649/1009,loss = 1.8334792852401733\n",
      "epoch650/1009,loss = 1.8927096128463745\n",
      "epoch651/1009,loss = 1.8187562227249146\n",
      "epoch652/1009,loss = 1.8950414657592773\n",
      "epoch653/1009,loss = 1.7733045816421509\n",
      "epoch654/1009,loss = 1.829883098602295\n",
      "epoch655/1009,loss = 1.7423118352890015\n",
      "epoch656/1009,loss = 1.73704195022583\n",
      "epoch657/1009,loss = 1.6732650995254517\n",
      "epoch658/1009,loss = 1.678723931312561\n",
      "epoch659/1009,loss = 1.8291447162628174\n",
      "epoch660/1009,loss = 1.8692151308059692\n",
      "epoch661/1009,loss = 1.7281867265701294\n",
      "epoch662/1009,loss = 1.7277203798294067\n",
      "epoch663/1009,loss = 1.7470051050186157\n",
      "epoch664/1009,loss = 1.7414189577102661\n",
      "epoch665/1009,loss = 1.7022185325622559\n",
      "epoch666/1009,loss = 1.8093563318252563\n",
      "epoch667/1009,loss = 1.7352123260498047\n",
      "epoch668/1009,loss = 1.7605884075164795\n",
      "epoch669/1009,loss = 1.7941808700561523\n",
      "epoch670/1009,loss = 1.8517199754714966\n",
      "epoch671/1009,loss = 1.734696865081787\n",
      "epoch672/1009,loss = 1.726503610610962\n",
      "epoch673/1009,loss = 1.7775170803070068\n",
      "epoch674/1009,loss = 1.8474754095077515\n",
      "epoch675/1009,loss = 1.702082872390747\n",
      "epoch676/1009,loss = 1.836228609085083\n",
      "epoch677/1009,loss = 1.7577707767486572\n",
      "epoch678/1009,loss = 1.7181504964828491\n",
      "epoch679/1009,loss = 1.7318272590637207\n",
      "epoch680/1009,loss = 1.8046793937683105\n",
      "epoch681/1009,loss = 1.6225076913833618\n",
      "epoch682/1009,loss = 1.7905254364013672\n",
      "epoch683/1009,loss = 1.817718505859375\n",
      "epoch684/1009,loss = 1.739975094795227\n",
      "epoch685/1009,loss = 1.75376558303833\n",
      "epoch686/1009,loss = 1.7932370901107788\n",
      "epoch687/1009,loss = 1.6989917755126953\n",
      "epoch688/1009,loss = 1.726029634475708\n",
      "epoch689/1009,loss = 1.6142728328704834\n",
      "epoch690/1009,loss = 1.964573860168457\n",
      "epoch691/1009,loss = 1.7339931726455688\n",
      "epoch692/1009,loss = 1.9138243198394775\n",
      "epoch693/1009,loss = 1.7090378999710083\n",
      "epoch694/1009,loss = 1.7105190753936768\n",
      "epoch695/1009,loss = 1.732088327407837\n",
      "epoch696/1009,loss = 1.6215192079544067\n",
      "epoch697/1009,loss = 1.6697189807891846\n",
      "epoch698/1009,loss = 1.6289997100830078\n",
      "epoch699/1009,loss = 1.7175108194351196\n",
      "epoch700/1009,loss = 1.7504668235778809\n",
      "epoch701/1009,loss = 1.9231139421463013\n",
      "epoch702/1009,loss = 1.6508733034133911\n",
      "epoch703/1009,loss = 1.6631749868392944\n",
      "epoch704/1009,loss = 1.6439040899276733\n",
      "epoch705/1009,loss = 1.651196002960205\n",
      "epoch706/1009,loss = 1.7556778192520142\n",
      "epoch707/1009,loss = 1.9511547088623047\n",
      "epoch708/1009,loss = 1.8147237300872803\n",
      "epoch709/1009,loss = 1.7316657304763794\n",
      "epoch710/1009,loss = 1.7143399715423584\n",
      "epoch711/1009,loss = 1.7127776145935059\n",
      "epoch712/1009,loss = 1.663833737373352\n",
      "epoch713/1009,loss = 1.6179293394088745\n",
      "epoch714/1009,loss = 1.7367017269134521\n",
      "epoch715/1009,loss = 1.6869415044784546\n",
      "epoch716/1009,loss = 1.8105182647705078\n",
      "epoch717/1009,loss = 1.6168065071105957\n",
      "epoch718/1009,loss = 1.7773411273956299\n",
      "epoch719/1009,loss = 1.7874538898468018\n",
      "epoch720/1009,loss = 1.7634698152542114\n",
      "epoch721/1009,loss = 1.7097904682159424\n",
      "epoch722/1009,loss = 1.680098056793213\n",
      "epoch723/1009,loss = 1.7579632997512817\n",
      "epoch724/1009,loss = 1.5672775506973267\n",
      "epoch725/1009,loss = 1.7291409969329834\n",
      "epoch726/1009,loss = 1.7031384706497192\n",
      "epoch727/1009,loss = 1.6271511316299438\n",
      "epoch728/1009,loss = 1.659492015838623\n",
      "epoch729/1009,loss = 1.7135158777236938\n",
      "epoch730/1009,loss = 1.667885661125183\n",
      "epoch731/1009,loss = 1.774686574935913\n",
      "epoch732/1009,loss = 1.6216694116592407\n",
      "epoch733/1009,loss = 1.6190799474716187\n",
      "epoch734/1009,loss = 1.6616042852401733\n",
      "epoch735/1009,loss = 1.613716721534729\n",
      "epoch736/1009,loss = 1.7396337985992432\n",
      "epoch737/1009,loss = 1.7152645587921143\n",
      "epoch738/1009,loss = 1.6649762392044067\n",
      "epoch739/1009,loss = 1.6718499660491943\n",
      "epoch740/1009,loss = 1.7641934156417847\n",
      "epoch741/1009,loss = 1.601796269416809\n",
      "epoch742/1009,loss = 1.639721393585205\n",
      "epoch743/1009,loss = 1.6903767585754395\n",
      "epoch744/1009,loss = 1.739532470703125\n",
      "epoch745/1009,loss = 1.609182596206665\n",
      "epoch746/1009,loss = 1.6871670484542847\n",
      "epoch747/1009,loss = 1.630476474761963\n",
      "epoch748/1009,loss = 1.6033151149749756\n",
      "epoch749/1009,loss = 1.7859644889831543\n",
      "epoch750/1009,loss = 1.5657124519348145\n",
      "epoch751/1009,loss = 1.62284255027771\n",
      "epoch752/1009,loss = 1.7255216836929321\n",
      "epoch753/1009,loss = 1.6496843099594116\n",
      "epoch754/1009,loss = 1.574949026107788\n",
      "epoch755/1009,loss = 1.738069772720337\n",
      "epoch756/1009,loss = 1.7937885522842407\n",
      "epoch757/1009,loss = 1.7212598323822021\n",
      "epoch758/1009,loss = 1.695888876914978\n",
      "epoch759/1009,loss = 1.6435118913650513\n",
      "epoch760/1009,loss = 1.6278927326202393\n",
      "epoch761/1009,loss = 1.621085524559021\n",
      "epoch762/1009,loss = 1.4797261953353882\n",
      "epoch763/1009,loss = 1.5909851789474487\n",
      "epoch764/1009,loss = 1.6970821619033813\n",
      "epoch765/1009,loss = 1.6057672500610352\n",
      "epoch766/1009,loss = 1.5461806058883667\n",
      "epoch767/1009,loss = 1.645337700843811\n",
      "epoch768/1009,loss = 1.774884581565857\n",
      "epoch769/1009,loss = 1.700226902961731\n",
      "epoch770/1009,loss = 1.6533970832824707\n",
      "epoch771/1009,loss = 1.7040948867797852\n",
      "epoch772/1009,loss = 1.6657497882843018\n",
      "epoch773/1009,loss = 1.6597896814346313\n",
      "epoch774/1009,loss = 1.7410334348678589\n",
      "epoch775/1009,loss = 1.656459093093872\n",
      "epoch776/1009,loss = 1.7130807638168335\n",
      "epoch777/1009,loss = 1.754184603691101\n",
      "epoch778/1009,loss = 1.6607781648635864\n",
      "epoch779/1009,loss = 1.619214653968811\n",
      "epoch780/1009,loss = 1.6329606771469116\n",
      "epoch781/1009,loss = 1.6210726499557495\n",
      "epoch782/1009,loss = 1.6196377277374268\n",
      "epoch783/1009,loss = 1.713046908378601\n",
      "epoch784/1009,loss = 1.6453036069869995\n",
      "epoch785/1009,loss = 1.7408394813537598\n",
      "epoch786/1009,loss = 1.7563003301620483\n",
      "epoch787/1009,loss = 1.6893633604049683\n",
      "epoch788/1009,loss = 1.6077055931091309\n",
      "epoch789/1009,loss = 1.6070657968521118\n",
      "epoch790/1009,loss = 1.496140718460083\n",
      "epoch791/1009,loss = 1.624581217765808\n",
      "epoch792/1009,loss = 1.698194146156311\n",
      "epoch793/1009,loss = 1.6821092367172241\n",
      "epoch794/1009,loss = 1.4707015752792358\n",
      "epoch795/1009,loss = 1.5951292514801025\n",
      "epoch796/1009,loss = 1.6567370891571045\n",
      "epoch797/1009,loss = 1.5652074813842773\n",
      "epoch798/1009,loss = 1.6855717897415161\n",
      "epoch799/1009,loss = 1.660857081413269\n",
      "epoch800/1009,loss = 1.6466671228408813\n",
      "epoch801/1009,loss = 1.5816177129745483\n",
      "epoch802/1009,loss = 1.7594190835952759\n",
      "epoch803/1009,loss = 1.6144994497299194\n",
      "epoch804/1009,loss = 1.58502197265625\n",
      "epoch805/1009,loss = 1.7619929313659668\n",
      "epoch806/1009,loss = 1.5798699855804443\n",
      "epoch807/1009,loss = 1.6084471940994263\n",
      "epoch808/1009,loss = 1.5529483556747437\n",
      "epoch809/1009,loss = 1.5251375436782837\n",
      "epoch810/1009,loss = 1.6095640659332275\n",
      "epoch811/1009,loss = 1.7319426536560059\n",
      "epoch812/1009,loss = 1.479889988899231\n",
      "epoch813/1009,loss = 1.577592372894287\n",
      "epoch814/1009,loss = 1.6091471910476685\n",
      "epoch815/1009,loss = 1.606495976448059\n",
      "epoch816/1009,loss = 1.606491208076477\n",
      "epoch817/1009,loss = 1.7129367589950562\n",
      "epoch818/1009,loss = 1.5766947269439697\n",
      "epoch819/1009,loss = 1.5117727518081665\n",
      "epoch820/1009,loss = 1.6123005151748657\n",
      "epoch821/1009,loss = 1.5923749208450317\n",
      "epoch822/1009,loss = 1.551804780960083\n",
      "epoch823/1009,loss = 1.6836917400360107\n",
      "epoch824/1009,loss = 1.615984559059143\n",
      "epoch825/1009,loss = 1.683017611503601\n",
      "epoch826/1009,loss = 1.5854090452194214\n",
      "epoch827/1009,loss = 1.6957534551620483\n",
      "epoch828/1009,loss = 1.5783214569091797\n",
      "epoch829/1009,loss = 1.5480942726135254\n",
      "epoch830/1009,loss = 1.5411686897277832\n",
      "epoch831/1009,loss = 1.592002272605896\n",
      "epoch832/1009,loss = 1.6015417575836182\n",
      "epoch833/1009,loss = 1.57735013961792\n",
      "epoch834/1009,loss = 1.638056755065918\n",
      "epoch835/1009,loss = 1.61981201171875\n",
      "epoch836/1009,loss = 1.6700809001922607\n",
      "epoch837/1009,loss = 1.6577644348144531\n",
      "epoch838/1009,loss = 1.5275161266326904\n",
      "epoch839/1009,loss = 1.689361572265625\n",
      "epoch840/1009,loss = 1.6243078708648682\n",
      "epoch841/1009,loss = 1.4897123575210571\n",
      "epoch842/1009,loss = 1.6982463598251343\n",
      "epoch843/1009,loss = 1.5418497323989868\n",
      "epoch844/1009,loss = 1.6102566719055176\n",
      "epoch845/1009,loss = 1.7195255756378174\n",
      "epoch846/1009,loss = 1.5326285362243652\n",
      "epoch847/1009,loss = 1.5802236795425415\n",
      "epoch848/1009,loss = 1.5841113328933716\n",
      "epoch849/1009,loss = 1.5587838888168335\n",
      "epoch850/1009,loss = 1.5898020267486572\n",
      "epoch851/1009,loss = 1.5936652421951294\n",
      "epoch852/1009,loss = 1.5466513633728027\n",
      "epoch853/1009,loss = 1.4925600290298462\n",
      "epoch854/1009,loss = 1.6506333351135254\n",
      "epoch855/1009,loss = 1.5557901859283447\n",
      "epoch856/1009,loss = 1.778610348701477\n",
      "epoch857/1009,loss = 1.7292964458465576\n",
      "epoch858/1009,loss = 1.6830235719680786\n",
      "epoch859/1009,loss = 1.661468267440796\n",
      "epoch860/1009,loss = 1.5829511880874634\n",
      "epoch861/1009,loss = 1.5929672718048096\n",
      "epoch862/1009,loss = 1.4883613586425781\n",
      "epoch863/1009,loss = 1.5030945539474487\n",
      "epoch864/1009,loss = 1.6139119863510132\n",
      "epoch865/1009,loss = 1.5957529544830322\n",
      "epoch866/1009,loss = 1.6063340902328491\n",
      "epoch867/1009,loss = 1.5777652263641357\n",
      "epoch868/1009,loss = 1.5574146509170532\n",
      "epoch869/1009,loss = 1.5928806066513062\n",
      "epoch870/1009,loss = 1.5981367826461792\n",
      "epoch871/1009,loss = 1.6316384077072144\n",
      "epoch872/1009,loss = 1.5133602619171143\n",
      "epoch873/1009,loss = 1.538417100906372\n",
      "epoch874/1009,loss = 1.5791690349578857\n",
      "epoch875/1009,loss = 1.5875649452209473\n",
      "epoch876/1009,loss = 1.54423189163208\n",
      "epoch877/1009,loss = 1.6031588315963745\n",
      "epoch878/1009,loss = 1.660679578781128\n",
      "epoch879/1009,loss = 1.5291533470153809\n",
      "epoch880/1009,loss = 1.6634420156478882\n",
      "epoch881/1009,loss = 1.5213549137115479\n",
      "epoch882/1009,loss = 1.6127575635910034\n",
      "epoch883/1009,loss = 1.5199745893478394\n",
      "epoch884/1009,loss = 1.582326054573059\n",
      "epoch885/1009,loss = 1.5788476467132568\n",
      "epoch886/1009,loss = 1.5603876113891602\n",
      "epoch887/1009,loss = 1.5573105812072754\n",
      "epoch888/1009,loss = 1.5016065835952759\n",
      "epoch889/1009,loss = 1.6889466047286987\n",
      "epoch890/1009,loss = 1.5617899894714355\n",
      "epoch891/1009,loss = 1.5179212093353271\n",
      "epoch892/1009,loss = 1.5479910373687744\n",
      "epoch893/1009,loss = 1.5551115274429321\n",
      "epoch894/1009,loss = 1.5736255645751953\n",
      "epoch895/1009,loss = 1.5859509706497192\n",
      "epoch896/1009,loss = 1.5840505361557007\n",
      "epoch897/1009,loss = 1.5645703077316284\n",
      "epoch898/1009,loss = 1.5312089920043945\n",
      "epoch899/1009,loss = 1.5533767938613892\n",
      "epoch900/1009,loss = 1.5680984258651733\n",
      "epoch901/1009,loss = 1.6212358474731445\n",
      "epoch902/1009,loss = 1.6080721616744995\n",
      "epoch903/1009,loss = 1.6522645950317383\n",
      "epoch904/1009,loss = 1.612092137336731\n",
      "epoch905/1009,loss = 1.5463435649871826\n",
      "epoch906/1009,loss = 1.6611775159835815\n",
      "epoch907/1009,loss = 1.5494190454483032\n",
      "epoch908/1009,loss = 1.4978655576705933\n",
      "epoch909/1009,loss = 1.578859567642212\n",
      "epoch910/1009,loss = 1.6775017976760864\n",
      "epoch911/1009,loss = 1.5246984958648682\n",
      "epoch912/1009,loss = 1.549871802330017\n",
      "epoch913/1009,loss = 1.5890600681304932\n",
      "epoch914/1009,loss = 1.5905672311782837\n",
      "epoch915/1009,loss = 1.6448030471801758\n",
      "epoch916/1009,loss = 1.3899084329605103\n",
      "epoch917/1009,loss = 1.592681884765625\n",
      "epoch918/1009,loss = 1.695239543914795\n",
      "epoch919/1009,loss = 1.536002516746521\n",
      "epoch920/1009,loss = 1.5914994478225708\n",
      "epoch921/1009,loss = 1.5245554447174072\n",
      "epoch922/1009,loss = 1.606055736541748\n",
      "epoch923/1009,loss = 1.6131833791732788\n",
      "epoch924/1009,loss = 1.5155123472213745\n",
      "epoch925/1009,loss = 1.5703948736190796\n",
      "epoch926/1009,loss = 1.6766520738601685\n",
      "epoch927/1009,loss = 1.5158480405807495\n",
      "epoch928/1009,loss = 1.4287523031234741\n",
      "epoch929/1009,loss = 1.519559621810913\n",
      "epoch930/1009,loss = 1.6351044178009033\n",
      "epoch931/1009,loss = 1.6200315952301025\n",
      "epoch932/1009,loss = 1.597566843032837\n",
      "epoch933/1009,loss = 1.4930696487426758\n",
      "epoch934/1009,loss = 1.6104817390441895\n",
      "epoch935/1009,loss = 1.4762428998947144\n",
      "epoch936/1009,loss = 1.4428555965423584\n",
      "epoch937/1009,loss = 1.5506621599197388\n",
      "epoch938/1009,loss = 1.585952877998352\n",
      "epoch939/1009,loss = 1.5463536977767944\n",
      "epoch940/1009,loss = 1.689635992050171\n",
      "epoch941/1009,loss = 1.4741225242614746\n",
      "epoch942/1009,loss = 1.4107762575149536\n",
      "epoch943/1009,loss = 1.4866496324539185\n",
      "epoch944/1009,loss = 1.4681370258331299\n",
      "epoch945/1009,loss = 1.4992393255233765\n",
      "epoch946/1009,loss = 1.5595394372940063\n",
      "epoch947/1009,loss = 1.6325589418411255\n",
      "epoch948/1009,loss = 1.5070774555206299\n",
      "epoch949/1009,loss = 1.6116336584091187\n",
      "epoch950/1009,loss = 1.5731674432754517\n",
      "epoch951/1009,loss = 1.6111570596694946\n",
      "epoch952/1009,loss = 1.4873285293579102\n",
      "epoch953/1009,loss = 1.5847282409667969\n",
      "epoch954/1009,loss = 1.5006061792373657\n",
      "epoch955/1009,loss = 1.6501007080078125\n",
      "epoch956/1009,loss = 1.5354585647583008\n",
      "epoch957/1009,loss = 1.5412535667419434\n",
      "epoch958/1009,loss = 1.5815496444702148\n",
      "epoch959/1009,loss = 1.5536667108535767\n",
      "epoch960/1009,loss = 1.5606443881988525\n",
      "epoch961/1009,loss = 1.456870675086975\n",
      "epoch962/1009,loss = 1.5127850770950317\n",
      "epoch963/1009,loss = 1.5098419189453125\n",
      "epoch964/1009,loss = 1.441956639289856\n",
      "epoch965/1009,loss = 1.6037243604660034\n",
      "epoch966/1009,loss = 1.4420069456100464\n",
      "epoch967/1009,loss = 1.629621148109436\n",
      "epoch968/1009,loss = 1.6456393003463745\n",
      "epoch969/1009,loss = 1.5376546382904053\n",
      "epoch970/1009,loss = 1.4513013362884521\n",
      "epoch971/1009,loss = 1.5687768459320068\n",
      "epoch972/1009,loss = 1.3829212188720703\n",
      "epoch973/1009,loss = 1.5348551273345947\n",
      "epoch974/1009,loss = 1.5687520503997803\n",
      "epoch975/1009,loss = 1.4730674028396606\n",
      "epoch976/1009,loss = 1.6217490434646606\n",
      "epoch977/1009,loss = 1.4827557802200317\n",
      "epoch978/1009,loss = 1.4698647260665894\n",
      "epoch979/1009,loss = 1.4591476917266846\n",
      "epoch980/1009,loss = 1.4531028270721436\n",
      "epoch981/1009,loss = 1.5502536296844482\n",
      "epoch982/1009,loss = 1.485007643699646\n",
      "epoch983/1009,loss = 1.5850855112075806\n",
      "epoch984/1009,loss = 1.39491605758667\n",
      "epoch985/1009,loss = 1.526676893234253\n",
      "epoch986/1009,loss = 1.3820602893829346\n",
      "epoch987/1009,loss = 1.5251401662826538\n",
      "epoch988/1009,loss = 1.5322157144546509\n",
      "epoch989/1009,loss = 1.4393640756607056\n",
      "epoch990/1009,loss = 1.6140966415405273\n",
      "epoch991/1009,loss = 1.4612714052200317\n",
      "epoch992/1009,loss = 1.49318528175354\n",
      "epoch993/1009,loss = 1.4428608417510986\n",
      "epoch994/1009,loss = 1.5147150754928589\n",
      "epoch995/1009,loss = 1.594387173652649\n",
      "epoch996/1009,loss = 1.4236646890640259\n",
      "epoch997/1009,loss = 1.5922292470932007\n",
      "epoch998/1009,loss = 1.4079103469848633\n",
      "epoch999/1009,loss = 1.42354154586792\n",
      "epoch1000/1009,loss = 1.5648260116577148\n",
      "epoch1001/1009,loss = 1.6193649768829346\n",
      "epoch1002/1009,loss = 1.5740954875946045\n",
      "epoch1003/1009,loss = 1.505802035331726\n",
      "epoch1004/1009,loss = 1.4181314706802368\n",
      "epoch1005/1009,loss = 1.6244938373565674\n",
      "epoch1006/1009,loss = 1.544234037399292\n",
      "epoch1007/1009,loss = 1.3405089378356934\n",
      "epoch1008/1009,loss = 1.507889986038208\n",
      "Total time: 304.27877593040466\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x19f8d7dfc90>]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "t1 = time.time() # timing \n",
    "\n",
    "for epoch in range(n_epoch): # start training\n",
    "    np.random.shuffle(train_ind) # shuffle\n",
    "    \n",
    "    for batch_i in range(0, train_size, batch_size): # batch_i: i'th batch start index\n",
    "        \n",
    "        # create minibatch_i\n",
    "        index_list = train_ind[batch_i:(batch_i+batch_size)] # get i'th batch's index list\n",
    "        minibatch = [train[id]  for id in index_list ] # from index get i'th minibatch list\n",
    "        minibatch_size = len(minibatch) # get i'th minibatch size\n",
    "        \n",
    "        # transform input name: char -> tensor\n",
    "        input, actual_len, target = names2tensor(minibatch) # input: each name's one-hot tensor, actual_len: actual lenth of each name\n",
    "        input = input.to(device=device) # transfer input to device\n",
    "        target = target.to(device=device) # transfer input to device\n",
    "        max_name_len = input.shape[0] # by definition of names2tensor\n",
    "        \n",
    "        # initialization \n",
    "        hidden = lstm.init_hidden(minibatch_size,device=device) # initialize hidden layer\n",
    "        MemCell = lstm.init_MemCell(minibatch_size,device=device) # initialize MemCell\n",
    "        \n",
    "        # compute loss function\n",
    "        loss = 0.0 # initialize loss function\n",
    "        \n",
    "        for name_i in range(max_name_len): # put data into LSTM char by char\n",
    "            output, hidden, MemCell = lstm(input[name_i], hidden, MemCell) #input[char_i]\n",
    "            loss_i = lossfn(output,target[name_i])\n",
    "            valid = torch.tensor( (name_i < actual_len).astype(int)).to(device=device)\n",
    "            loss += loss_i * valid\n",
    "        \n",
    "        loss = torch.mean(loss / torch.tensor(actual_len).to(device=device))    \n",
    "        \n",
    "        # opt the loss fn\n",
    "        opt.zero_grad() # initialize optimizer\n",
    "        loss.backward() # backward for gradient\n",
    "        opt.step() # update params\n",
    "        \n",
    "        losses.append(loss.item()) # ?\n",
    "     \n",
    "    print(f\"epoch{epoch}/{n_epoch},loss = {loss.item()}\")\n",
    "            \n",
    "t2 = time.time()\n",
    "\n",
    "print(f\"Total time: {t2-t1}\")\n",
    "\n",
    "plt.plot(losses)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***TEST OUTPUT***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(\n",
       "  (X2F): Linear(in_features=283, out_features=256, bias=True)\n",
       "  (X2I): Linear(in_features=283, out_features=256, bias=True)\n",
       "  (X2O): Linear(in_features=283, out_features=256, bias=True)\n",
       "  (X2Ct): Linear(in_features=283, out_features=256, bias=True)\n",
       "  (O2O): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (logsoftmax): LogSoftmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test output ???\n",
    "\n",
    "torch.save(lstm.state_dict(), \"name.pt\")\n",
    "lstm.load_state_dict(torch.load(\"name.pt\", map_location=device))\n",
    "lstm.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "near\n"
     ]
    }
   ],
   "source": [
    "first_char = list('abcdefghijklmnoprstuvwxyz')\n",
    "\n",
    "def gen_FirstChar():\n",
    "    \"\"\"generate first character from a~z\"\"\"\n",
    "    return np.random.choice(first_char,1)[0]\n",
    "\n",
    "def gen_Names(max_lenth = 10):\n",
    "    lstm.eval() # eval mode (because of dropout)\n",
    "    \n",
    "    first_char = gen_FirstChar() # randomly generate form 'a~z'\n",
    "    input = char2tensor(first_char).to(device=device) # get input into tensor\n",
    "    char_ind = [torch.argmax(input).item()] # the index of this character (in alphabet), we need this for char recovery\n",
    "    \n",
    "    hidden = lstm.init_hidden(batch_size=1,device=device)\n",
    "    memcell = lstm.init_MemCell(batch_size=1,device=device)\n",
    "    \n",
    "    for chr_i in range(max_lenth - 1): # now processing the i'th char\n",
    "        output, hidden, memcell = lstm(input, hidden,memcell) # put data into lstm\n",
    "        index = torch.argmax(output).item() # get the predicted char\n",
    "        if index == charset_size - 1: # last char(<EOS>)\n",
    "            break\n",
    "        char_ind.append(index) # put current char idx into total idx\n",
    "        input.zero_() #?\n",
    "        input[0,index] = 1.0 # set current index = 1, telling the model the predicted one\n",
    "                 \n",
    "    return char_ind\n",
    "\n",
    "np.random.seed(123)\n",
    "torch.random.manual_seed(123)\n",
    "index = gen_Names(10)\n",
    "\n",
    "print(\"\".join([dictionary[i] for i in index])) # put the char together into a name\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['newsome' 'colley' 'colley' 'greene' 'steel'\n",
      " 'upson' 'kenneth' 'xone' 'barrow' 'allam'\n",
      " 'steel' 'parker' 'jenkins' 'allam' 'orme'\n",
      " 'allam' 'parker' 'upson' 'orme' 'elliston'\n",
      " 'allam' 'robert' 'elliston' 'steel' 'yardley'\n",
      " 'downes' 'colley' 'viney' 'harries' 'colley'\n",
      " 'viney' 'parker' 'zaoui' 'robert' 'harries'\n",
      " 'jenkins' 'downes' 'viney' 'greene' 'barrow'\n",
      " 'waller' 'xone' 'colley' 'barrow' 'mackie'\n",
      " 'inglefield' 'downes' 'kenneth' 'farrelly'\n",
      " 'allam' 'laws' 'colley' 'kenneth' 'xone'\n",
      " 'newsome' 'tompkin' 'elliston' 'parker' 'laws'\n",
      " 'mackie' 'viney' 'greene' 'newsome' 'upson'\n",
      " 'robert' 'greene' 'orme' 'viney' 'harries'\n",
      " 'laws' 'xone' 'harries' 'barrow' 'laws'\n",
      " 'farrelly' 'yardley' 'tompkin' 'viney' 'zaoui'\n",
      " 'steel' 'mackie' 'tompkin' 'steel' 'barrow'\n",
      " 'upson' 'mackie' 'waller' 'jenkins' 'robert'\n",
      " 'zaoui' 'steel' 'xone' 'downes' 'downes' 'laws'\n",
      " 'waller' 'harries' 'jenkins' 'colley' 'downes'\n",
      " 'laws' 'downes' 'upson' 'zaoui' 'greene'\n",
      " 'jenkins' 'yardley' 'orme' 'greene' 'upson'\n",
      " 'greene' 'mackie' 'xone' 'greene' 'steel' 'orme'\n",
      " 'kenneth' 'downes' 'viney' 'downes' 'barrow'\n",
      " 'parker' 'newsome' 'robert' 'farrelly'\n",
      " 'inglefield' 'newsome' 'xone' 'orme' 'parker'\n",
      " 'inglefield' 'newsome' 'steel' 'allam' 'downes'\n",
      " 'barrow' 'upson' 'elliston' 'harries' 'greene'\n",
      " 'barrow' 'viney' 'mackie' 'downes' 'mackie'\n",
      " 'upson' 'harries' 'greene' 'zaoui' 'greene'\n",
      " 'newsome' 'mackie' 'viney' 'elliston' 'yardley'\n",
      " 'robert' 'allam' 'inglefield' 'zaoui' 'viney'\n",
      " 'newsome' 'newsome' 'inglefield' 'orme' 'greene'\n",
      " 'barrow' 'greene' 'inglefield' 'yardley'\n",
      " 'kenneth' 'mackie' 'mackie' 'kenneth' 'steel'\n",
      " 'harries' 'newsome' 'mackie' 'barrow' 'yardley'\n",
      " 'jenkins' 'orme' 'zaoui' 'yardley' 'barrow'\n",
      " 'downes' 'steel' 'zaoui' 'orme' 'yardley'\n",
      " 'farrelly' 'barrow' 'tompkin' 'farrelly'\n",
      " 'colley' 'tompkin' 'orme' 'newsome' 'downes'\n",
      " 'tompkin' 'orme']\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "torch.random.manual_seed(123)\n",
    "names = []\n",
    "for i in range(200):\n",
    "    ind = gen_Names(10)\n",
    "    names.append(\"\".join([dictionary[i] for i in ind]))\n",
    "np.set_printoptions(linewidth=50)\n",
    "print(np.array(names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
