{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "294f54c3",
   "metadata": {},
   "source": [
    "# 分布式 Logistic 回归模型实现细节"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd303e5e",
   "metadata": {},
   "source": [
    "### 1. 准备工作"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4330a894",
   "metadata": {},
   "source": [
    "配置和启动 PySpark："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d9bba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "# 本地模式\n",
    "spark = SparkSession.builder.\\\n",
    "    master(\"local[*]\").\\\n",
    "    appName(\"Logistic Regression\").\\\n",
    "    getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "# sc.setLogLevel(\"ERROR\")\n",
    "print(spark)\n",
    "print(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ffbec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from scipy.special import expit, logit\n",
    "np.set_printoptions(linewidth=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b375df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# str => np.array\n",
    "def str_to_vec(line):\n",
    "    # 分割字符串\n",
    "    str_vec = line.split(\"\\t\")\n",
    "    # 将每一个元素从字符串变成数值型\n",
    "    num_vec = map(lambda s: float(s), str_vec)\n",
    "    # 创建 Numpy 向量\n",
    "    return np.fromiter(num_vec, dtype=float)\n",
    "\n",
    "# Iter[str] => Iter[matrix]\n",
    "def part_to_mat(iterator):\n",
    "    # Iter[str] => Iter[np.array]\n",
    "    iter_arr = map(str_to_vec, iterator)\n",
    "\n",
    "    # Iter[np.array] => list(np.array)\n",
    "    dat = list(iter_arr)\n",
    "\n",
    "    # list(np.array) => matrix\n",
    "    if len(dat) < 1:  # Test zero iterator\n",
    "        mat = np.array([])\n",
    "    else:\n",
    "        mat = np.vstack(dat)\n",
    "\n",
    "    # matrix => Iter[matrix]\n",
    "    yield mat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ca1b07",
   "metadata": {},
   "source": [
    "### 2. 实验1：目标函数计算"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4a0ff4",
   "metadata": {},
   "source": [
    "以牛顿法为例，直接计算 $\\log(prob)$ 和 $\\log(1 - prob)$。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d437358b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_stats(part_mat, beta_old):\n",
    "    # 提取 X 和 y\n",
    "    y = part_mat[:, 0]\n",
    "    x = part_mat[:, 1:]\n",
    "    # X * beta\n",
    "    xb = x.dot(beta_old)\n",
    "    # rho(X * beta)\n",
    "    prob = expit(xb)\n",
    "    # W 的对角线元素\n",
    "    w = prob * (1.0 - prob) + 1e-6\n",
    "    # X'W，数组广播操作，避免生成完整的 W\n",
    "    xtw = x.transpose() * w\n",
    "    # X'WX\n",
    "    xtwx = xtw.dot(x)\n",
    "    # X'Wz\n",
    "    z = xb + (y - prob) / w\n",
    "    xtwz = xtw.dot(z)\n",
    "    # 目标函数：sum(y * log(prob) + (1 - y) * log(1 - prob))\n",
    "    ####### 注意！！以下并不是稳定的算法！！需使用 Softplus 函数进行改写 #######\n",
    "    objfn = -np.sum(y * np.log(prob) + (1.0 - y) * np.log(1.0 - prob))\n",
    "    ########################################################################\n",
    "    return xtwx, xtwz, objfn\n",
    "\n",
    "file = sc.textFile(\"data/logistic.txt\")\n",
    "dat = file.mapPartitions(part_to_mat).filter(lambda x: x.shape[0] > 0)\n",
    "\n",
    "# 根据数据动态获取维度，不要使用之前模拟时的变量\n",
    "p = dat.first().shape[1] - 1\n",
    "# beta 初始化为 0 向量\n",
    "beta_hat = np.zeros(p)\n",
    "# 记录目标函数值\n",
    "objvals = []\n",
    "\n",
    "# 最大迭代次数\n",
    "maxit = 10\n",
    "# 收敛条件\n",
    "eps = 1e-6\n",
    "\n",
    "t1 = time.time()\n",
    "for i in range(maxit):\n",
    "    # 完整数据的 X'WX 和 X'Wz 是各分区的加和\n",
    "    xtwx, xtwz, objfn = dat.map(lambda part: compute_stats(part, beta_hat)).\\\n",
    "        reduce(lambda x, y: (x[0] + y[0], x[1] + y[1], x[2] + y[2]))\n",
    "    # 计算新 beta\n",
    "    beta_new = np.linalg.solve(xtwx, xtwz)\n",
    "    # 计算 beta 的变化\n",
    "    resid = np.linalg.norm(beta_new - beta_hat)\n",
    "    print(f\"Iteration {i}, objfn = {objfn}, resid = {resid}\")\n",
    "    objvals.append(objfn)\n",
    "    # 如果 beta 几乎不再变化，退出循环\n",
    "    if resid < eps:\n",
    "        break\n",
    "    # 更新 beta\n",
    "    beta_hat = beta_new\n",
    "t2 = time.time()\n",
    "print(f\"\\nfinished in {t2 - t1} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfa1561",
   "metadata": {},
   "source": [
    "目标函数值出现 NaN，需更换计算目标函数的方法：$\\log \\rho(x)=x-\\log(1+e^x)$，$\\log(1-\\rho(x))=-\\log(1+e^x)$。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a28ade",
   "metadata": {},
   "source": [
    "### 3. 实验2：RDD 缓存"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2c982a",
   "metadata": {},
   "source": [
    "重复上述实验，但对 RDD 进行缓存。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75993d43",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "file = sc.textFile(\"data/logistic.txt\")\n",
    "dat = file.mapPartitions(part_to_mat).filter(lambda x: x.shape[0] > 0)\n",
    "\n",
    "##### RDD 缓存 #####\n",
    "dat.cache()\n",
    "####################\n",
    "\n",
    "# 根据数据动态获取维度，不要使用之前模拟时的变量\n",
    "p = dat.first().shape[1] - 1\n",
    "# beta 初始化为 0 向量\n",
    "beta_hat = np.zeros(p)\n",
    "# 记录目标函数值\n",
    "objvals = []\n",
    "\n",
    "# 最大迭代次数\n",
    "maxit = 10\n",
    "# 收敛条件\n",
    "eps = 1e-6\n",
    "\n",
    "t1 = time.time()\n",
    "for i in range(maxit):\n",
    "    # 完整数据的 X'WX 和 X'Wz 是各分区的加和\n",
    "    xtwx, xtwz, objfn = dat.map(lambda part: compute_stats(part, beta_hat)).\\\n",
    "        reduce(lambda x, y: (x[0] + y[0], x[1] + y[1], x[2] + y[2]))\n",
    "    # 计算新 beta\n",
    "    beta_new = np.linalg.solve(xtwx, xtwz)\n",
    "    # 计算 beta 的变化\n",
    "    resid = np.linalg.norm(beta_new - beta_hat)\n",
    "    print(f\"Iteration {i}, objfn = {objfn}, resid = {resid}\")\n",
    "    objvals.append(objfn)\n",
    "    # 如果 beta 几乎不再变化，退出循环\n",
    "    if resid < eps:\n",
    "        break\n",
    "    # 更新 beta\n",
    "    beta_hat = beta_new\n",
    "t2 = time.time()\n",
    "print(f\"\\nfinished in {t2 - t1} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2b0b30",
   "metadata": {},
   "source": [
    "### 实验3：调整内存上限"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47318a40",
   "metadata": {},
   "source": [
    "生成一个更高维的数据，测试缓存内存占用，$p:100\\rightarrow 1000$。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48f2930",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "n = 100000\n",
    "p = 1000\n",
    "x = np.random.normal(size=(n, p))\n",
    "beta = np.random.normal(size=p)\n",
    "prob = expit(x.dot(beta))  # p = 1 / (1 + exp(-x * beta))\n",
    "y = np.random.binomial(1, prob, size=n)\n",
    "dat = np.hstack((y.reshape(n, 1), x))\n",
    "np.savetxt(\"data/logistic_large.txt\", dat, fmt=\"%f\", delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5392b406",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = sc.textFile(\"data/logistic_large.txt\")\n",
    "dat = file.mapPartitions(part_to_mat).filter(lambda x: x.shape[0] > 0)\n",
    "print(dat.getNumPartitions())\n",
    "\n",
    "##### RDD 缓存 #####\n",
    "dat.cache()\n",
    "####################\n",
    "\n",
    "# 根据数据动态获取维度，不要使用之前模拟时的变量\n",
    "p = dat.first().shape[1] - 1\n",
    "# beta 初始化为 0 向量\n",
    "beta_hat = np.zeros(p)\n",
    "# 记录目标函数值\n",
    "objvals = []\n",
    "\n",
    "# 最大迭代次数\n",
    "maxit = 10\n",
    "# 收敛条件\n",
    "eps = 1e-6\n",
    "\n",
    "t1 = time.time()\n",
    "for i in range(maxit):\n",
    "    # 完整数据的 X'WX 和 X'Wz 是各分区的加和\n",
    "    xtwx, xtwz, objfn = dat.map(lambda part: compute_stats(part, beta_hat)).\\\n",
    "        reduce(lambda x, y: (x[0] + y[0], x[1] + y[1], x[2] + y[2]))\n",
    "    # 计算新 beta\n",
    "    beta_new = np.linalg.solve(xtwx, xtwz)\n",
    "    # 计算 beta 的变化\n",
    "    resid = np.linalg.norm(beta_new - beta_hat)\n",
    "    print(f\"Iteration {i}, objfn = {objfn}, resid = {resid}\")\n",
    "    objvals.append(objfn)\n",
    "    # 如果 beta 几乎不再变化，退出循环\n",
    "    if resid < eps:\n",
    "        break\n",
    "    # 更新 beta\n",
    "    beta_hat = beta_new\n",
    "t2 = time.time()\n",
    "print(f\"\\nfinished in {t2 - t1} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d375e8",
   "metadata": {},
   "source": [
    "关闭 Spark 连接："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e9f36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d032735b",
   "metadata": {},
   "source": [
    "建立一个新的 Spark 进程，增加内存上限："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2470bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "# 本地模式\n",
    "spark = SparkSession.builder.\\\n",
    "    master(\"local[*]\").\\\n",
    "    config(\"spark.executor.memory\", \"2g\").\\\n",
    "    config(\"spark.driver.memory\", \"2g\").\\\n",
    "    appName(\"Logistic Regression\").\\\n",
    "    getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "# sc.setLogLevel(\"ERROR\")\n",
    "print(spark)\n",
    "print(sc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
