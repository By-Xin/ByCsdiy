{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 作业4：线性模型的分布式算法"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第1题"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先利用如下代码生成模拟数据，并写入文件。数据中最后一列代表因变量 $Y$，其余列为自变量 $X$。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(linewidth=100)\n",
    "np.random.seed(123)\n",
    "n = 100000\n",
    "p = 100\n",
    "x = np.random.normal(size=(n, p))\n",
    "beta = np.random.normal(size=p)\n",
    "y = 1.23 + x.dot(beta) + np.random.normal(scale=2.0, size=n)\n",
    "dat = np.hstack((x, y.reshape(n, 1)))\n",
    "np.savetxt(\"reg_data.txt\", dat, fmt=\"%.8f\", delimiter=\";\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请以单机模式启动 PySpark，使用4个 CPU 核心，并编写分布式程序，实现如下计算："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.session.SparkSession object at 0x000002280DDF40A0>\n",
      "<SparkContext master=local[4] appName=PySpark RDD>\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init(\"\")\n",
    "from pyspark.sql import SparkSession\n",
    "# 本地模式\n",
    "spark = SparkSession.builder.\\\n",
    "    master(\"local[4]\").\\\n",
    "    appName(\"PySpark RDD\").\\\n",
    "    getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel(\"ERROR\")\n",
    "print(spark)\n",
    "print(sc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 打印数据的前5行，并将每行的字符串截断至80个字符："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.08563060;0.99734545;0.28297850;-1.50629471;-0.57860025;1.65143654;-2.42667924\n",
      "0.64205469;-1.97788793;0.71226464;2.59830393;-0.02462598;0.03414213;0.17954948;-\n",
      "0.70331012;-0.59810533;2.20070210;0.68829693;-0.00630725;-0.20666230;-0.08652229\n",
      "0.76505485;-0.82898883;-0.65915131;0.61112355;-0.14401335;1.31660560;-0.70434215\n",
      "1.53409029;-0.52991410;-0.49097228;-1.30916531;-0.00866047;0.97681298;-1.7510703\n"
     ]
    }
   ],
   "source": [
    "file = sc.textFile(\"reg_data.txt\")\n",
    "text = file.map(lambda x: x[:80]).take(5)\n",
    "print(*text,sep='\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 将读取数据后得到的 RDD 按分区转为矩阵。使用默认分区数，无需重新分区。打印出转换后的第一个非空分区所包含的数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -1.0856306    0.99734545   0.2829785  ...   0.37940061  -0.37917643   3.72488966]\n",
      " [  0.64205469  -1.97788793   0.71226464 ...  -0.34126172  -0.21794626  10.98088055]\n",
      " [  0.70331012  -0.59810533   2.2007021  ...   0.16054442   0.81976061 -12.63028846]\n",
      " ...\n",
      " [ -0.30751248   0.1323937    2.33256448 ...   0.37475498  -1.37608098 -13.52353737]\n",
      " [ -0.02266014  -0.3014796    2.34502536 ...  -2.06082696  -1.20995417 -10.00714174]\n",
      " [  0.02415432  -0.3896902   -0.07492828 ...  -0.41935638  -1.68496516   8.33748658]]\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "def string_to_vector(line):\n",
    "    vector = line.split(\";\")\n",
    "    return np.array(vector, dtype=float)\n",
    "\n",
    "def partition_to_matrix (iterator):\n",
    "    iterator_vec = map(string_to_vector, iterator)\n",
    "    data = list(iterator_vec)\n",
    "    if len(data) < 1:\n",
    "        matrix = np.array([])\n",
    "    else:\n",
    "        matrix = np.vstack(data)\n",
    "    yield matrix\n",
    "\n",
    "data_partition = file.mapPartitions(partition_to_matrix)\n",
    "data_partition_nonempty = data_partition.filter(lambda x: x.shape[0] > 0)\n",
    "print(data_partition_nonempty.first())\n",
    "print(data_partition_nonempty.getNumPartitions())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 估计线性回归模型 $Y=X\\beta+\\varepsilon$ 的回归系数，**同时包含截距项**。要求**只使用一次** `reduce()`。\n",
    "\n",
    "$$\\hat \\beta = (X^TX)^{-1}X^TY$$\n",
    "$$X^*=[1:X]$$\n",
    "$${X^*}'(X^*,Y)=({X^*}'{X^*},{X^*}'Y)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.22841355 -0.58056172 -1.12947488  1.16031679  0.68276231  0.64063205 -1.69803101  0.87295008\n",
      " -0.6827681   1.21323821 -0.18532546 -0.60313748  0.45016343  1.54732259  0.93536575  0.33661885\n",
      " -0.62839196 -0.18223468  1.04004336  0.99530527 -0.22421889  0.26910036 -1.95584105  0.93200566\n",
      " -0.46663344 -1.30308226 -1.07451859 -0.9200001  -0.4751849  -0.41498631  0.0893936   0.74250157\n",
      "  0.44142653  0.78310696  0.0968675  -0.20661749  1.36408459 -0.84452182 -1.56303708 -0.03391736\n",
      "  0.05672465 -0.01335776 -0.31919022 -1.7366497  -1.35682179 -1.60938262 -1.28888311  0.92820726\n",
      "  0.9148462  -0.87189391 -1.11327839 -0.65324334 -1.54752238 -1.48016168 -1.40044728  0.06124555\n",
      " -2.06832355  0.23966887 -1.45310857 -0.4958114  -1.0917562   1.22608413  0.71866161  0.46548143\n",
      " -0.21573557  1.19919219 -0.18470024  0.41716831  0.48748654 -0.28702665 -0.92945413 -2.54835305\n",
      "  1.21073672 -0.41380347  0.40696645  0.74054168  1.59228068 -0.35873326  0.41181034 -1.44030368\n",
      " -0.47743396 -0.27652029 -1.65913574  1.16482342  0.42295274  0.22050512 -0.59462348  1.16788557\n",
      " -2.2204779  -0.5005211  -1.10794934  1.6138532  -1.31890072 -0.06216637  2.21620451  1.48179503\n",
      "  0.54913153 -0.73276144  0.4414304   2.14035783  1.68434134]\n"
     ]
    }
   ],
   "source": [
    "xt_xy = data_partition_nonempty.\\\n",
    "    map(lambda x: np.hstack((np.ones((np.shape(x)[0],1)),x))).\\\n",
    "    map(lambda x: x[:,:-1].transpose().dot(x) ).\\\n",
    "    reduce (lambda x,y: x+y)\n",
    "\n",
    "xt_x = xt_xy[:,:-1]\n",
    "xt_y = xt_xy[:,-1]\n",
    "\n",
    "hat_beta = np.linalg.solve(xt_x,xt_y)\n",
    "print(hat_beta)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 设计一个分布式算法，计算回归模型的 $R^2$。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "相关公式：\n",
    "$$SSR = \\sum (y_i-\\hat y_i)^2 = ||Y-X\\hat\\beta||_2$$\n",
    "$$SST = \\sum (y_i - \\bar y)^2 = \\sum y_i^2+n\\bar y^2-2\\bar y \\sum y_i $$\n",
    "$$ R^2 = 1 - SSR/SST$$\n",
    "\n",
    "假设：\n",
    "1. 已知$\\hat\\beta, [X,Y]$\n",
    "2. 数据经过mapPartition在多个矩阵中存储\n",
    "   \n",
    "计算过程：\n",
    "1. 扩充$X := [1,X]$\n",
    "2. 计算 $Y-X\\hat\\beta$，稍后对其进行平方求和\n",
    "3. 计算 $\\sum y_i, \\sum y_i^2$\n",
    "4. reduce，根据上述Rsquare公式进行整合计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116691.99105594002 11636386.644065393 397451.80241834675 100000\n",
      "R^2: 0.9654396241479573\n"
     ]
    }
   ],
   "source": [
    "sum_y, sum_y_sq, ssr, num = data_partition_nonempty.\\\n",
    "    map(lambda x: np.hstack((np.ones((np.shape(x)[0],1)),x))).\\\n",
    "    map(lambda x: (np.sum(x[:,-1]),np.sum(x[:,-1]**2),np.sum( ( x[:,-1] -  x[:,:-1].dot(hat_beta)  )**2,axis=0),np.shape(x)[0])).\\\n",
    "    reduce(lambda x,y:(x[0]+y[0],x[1]+y[1],x[2]+y[2],x[3]+y[3]) )\n",
    "print(sum_y,sum_y_sq, ssr, num)\n",
    "y_bar = sum_y/num\n",
    "sst = sum_y_sq + n*y_bar**2 -2*y_bar*sum_y\n",
    "R_sq = 1 - ssr/sst\n",
    "print(f\"R^2: {R_sq}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第2题"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) 考虑 Softplus 函数 $$\\mathrm{softplus}(x)=\\log(1+e^x)$$\n",
    "\n",
    "请利用 Numpy 编写一个函数 `softplus(x)`，令其可以接收一个向量或矩阵 `x`，返回 Softplus 函数在 `x` 上的取值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def softplus(x):\n",
    "    # 此处插入代码\n",
    "    print(\"softplus 1\")\n",
    "    return np.log(1+np.exp(x))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一个简单的测试："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softplus 1\n",
      "[0.00000000e+00 0.00000000e+00 4.53988992e-05 6.93147181e-01 1.31326169e+00 1.00000454e+01\n",
      " 1.00000000e+02            inf]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xinby\\AppData\\Local\\Temp\\ipykernel_26428\\3348825107.py:6: RuntimeWarning: overflow encountered in exp\n",
      "  return np.log(1+np.exp(x))\n"
     ]
    }
   ],
   "source": [
    "x = np.array([-1000.0, -100.0, -10.0, 0.0, 1.0, 10.0, 100.0, 1000.0])\n",
    "\n",
    "# 上面编写的函数\n",
    "print(softplus(x))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) 上述结果是否正常？如果出现异常取值，思考可能的原因是什么，并参照课件上的说明再次尝试编写 Softplus 函数。注意尽可能使用 Numpy 提供的向量化函数，避免使用循环。该函数需同时支持向量和矩阵参数。如果一切正常，可忽略此问题。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- *在测试$x=1000.0$时，提示发生了溢出，并且在数值返回的时候返回值为`inf`.*\n",
    "\n",
    "- *初步推断这是由于当$x$较大时，$e^x$指数函数的数值过大发生了溢出，导致计算的稳定性出现问题*\n",
    "\n",
    "- *为了改进，当$x\\ge0$时，改用如下等价表达形式$\\log(1+e^x) = \\log[e^x(e^{-x}+1)]=x+\\log(1+e^{-x})$以增强计算的稳定性*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softplus(x):\n",
    "    # 此处插入代码\n",
    "    print(\"softplus 2\")\n",
    "    ans = np.where(x>=0,np.log(1+np.exp(-x))+x,np.log(1+np.exp(x)))\n",
    "    return ans"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "但是上面这段代码是有问题的，在进行where的时候事实上这里还是都计算了两次，只不过用where选择了数值稳定的。这里通过绝对值对代码再次进行改进：\n",
    "\n",
    "$x>0, softplus=x+\\log(1+e^{-x})$\n",
    "\n",
    "$x<0, softplus=\\log(1+e^x)$\n",
    "\n",
    "因此\n",
    "\n",
    "可以将log部分统一整理为: $\\log(1+e^{-|x|})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softplus(x):\n",
    "    log_num = np.log(1+np.exp(-np.abs(x)))\n",
    "    ans = np.where(x>=0, x+log_num, log_num)\n",
    "    return ans"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "再次测试："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00000000e+00 0.00000000e+00 4.53988992e-05 6.93147181e-01 1.31326169e+00 1.00000454e+01\n",
      " 1.00000000e+02 1.00000000e+03]\n",
      "\n",
      "[[0.00000000e+00 0.00000000e+00]\n",
      " [4.53988992e-05 6.93147181e-01]\n",
      " [1.31326169e+00 1.00000454e+01]\n",
      " [1.00000000e+02 1.00000000e+03]]\n"
     ]
    }
   ],
   "source": [
    "print(softplus(x))\n",
    "print()\n",
    "print(softplus(x.reshape(4, 2)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第3题"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "利用如下代码生成模拟数据，其中数据第一列代表0-1因变量 $Y$，其余列为自变量 $X$。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import exp\n",
    "from scipy.special import expit\n",
    "\n",
    "np.random.seed(123)\n",
    "n = 100000\n",
    "p = 100\n",
    "x = np.random.normal(size=(n, p))\n",
    "beta = np.random.normal(size=p)\n",
    "prob = expit(-0.5 + x.dot(beta))  # p = 1 / (1 + exp(-x * beta))\n",
    "y = np.random.binomial(1, prob, size=n)\n",
    "dat = np.hstack((y.reshape(n, 1), x))\n",
    "np.savetxt(\"logistic_data.txt\", dat, fmt=\"%.8f\", delimiter=\"\\t\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 对上述数据建立 Logistic 回归模型。任选一种算法，估计 Logistic 回归的回归系数，**同时包含截距项**。请利用第2题中编写的 Softplus 函数，编写**数值稳定**的函数计算 Logistic 回归的目标函数和梯度。\n",
    "\n",
    "$$\\begin{aligned}\n",
    "f_{obj}&=-\\sum[ y_i\\log p_i+(1-y_i)\\log (1-p_i)]\\\\&=-\\sum [y_i(x\\beta-\\log(1+e^{x\\beta}))+(1-y_i)(-\\log (1+e^{x\\beta}))] \\\\&=-\\sum[ y_i(x\\beta-s(x\\beta))+(y_i-1)s(x\\beta) ]\n",
    "\\end{aligned}$$\n",
    "\n",
    "where $s(x) = \\log(1+e^x)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load softplus\n",
    "test = False\n",
    "def softplus(x):\n",
    "    # 此处插入代码\n",
    "    if (test): \n",
    "        print(f\"call func: softplus\")\n",
    "    ans = np.where(x>=0,np.log(1+np.exp(-x))+x,np.log(1+np.exp(x)))\n",
    "    if (test): \n",
    "        print(f\"return.shape:{ans.shape}\")\n",
    "        print(f\"end func: softplus \\n\")\n",
    "    return ans\n",
    "\n",
    "def sigmoid(x):\n",
    "    ans = np.where(x>0,1/(1+np.exp(-x)),exp(x)/(1+exp(x)))\n",
    "    return ans\n",
    "\n",
    "# load data to rdd\n",
    "def string_to_vector(line):\n",
    "    vector = line.split(\"\\t\")\n",
    "    vector = np.append(vector,1.0)\n",
    "    return np.array(vector, dtype=float)\n",
    "\n",
    "def partition_to_matrix (iterator):\n",
    "    iterator_vec = map(string_to_vector, iterator)\n",
    "    data = list(iterator_vec)\n",
    "    if len(data) < 1:\n",
    "        matrix = np.array([])\n",
    "    else:\n",
    "        matrix = np.vstack(data)\n",
    "    yield matrix\n",
    "\n",
    "file = sc.textFile(\"logistic_data.txt\")\n",
    "\n",
    "data_partition = file.mapPartitions(partition_to_matrix)\n",
    "data_partition_nonempty = data_partition.filter(lambda x: x.shape[0] > 0)\n",
    "data_partition_nonempty.cache()\n",
    "data_partition_nonempty.count()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, objfn = 69314.71805599453, resid = 1.5698521885255372\n",
      "Iteration 1, objfn = 32646.979227911244, resid = 1.3901997462268305\n",
      "Iteration 2, objfn = 21647.769318284514, resid = 1.7368788815875644\n",
      "Iteration 3, objfn = 16036.81715822243, resid = 2.0776610476266577\n",
      "Iteration 4, objfn = 13369.971015111047, resid = 2.0554425789459\n",
      "Iteration 5, objfn = 12424.605050958291, resid = 1.3106763115298687\n",
      "Iteration 6, objfn = 12255.539828228106, resid = 0.34684153390743866\n",
      "Iteration 7, objfn = 12248.214989925482, resid = 0.018344346618324184\n",
      "Iteration 8, objfn = 12248.196924487687, resid = 6.370796263421582e-05\n",
      "Iteration 9, objfn = 12248.196924271282, resid = 6.056472389209912e-08\n",
      "Accomplish!\n",
      "Final Iteration 9, objfn = 12248.196924271282, resid = 6.056472389209912e-08\n"
     ]
    }
   ],
   "source": [
    "# compute beta_hat fcn\n",
    "def compute_betahat(mat,beta_old):\n",
    "\n",
    "    if (test):\n",
    "        print(\"call fnc: comp_bhat\\n\")\n",
    "\n",
    "    y = mat[:,0]\n",
    "    x = mat[:,1:]\n",
    "    xbeta = x.dot(beta_old)\n",
    "    prob = sigmoid(xbeta) #这里的prob可以避免吗sigmoid（因为后面的objfn只用了softplus）？但是W该怎么算啊\n",
    "    w = prob * (1.0 - prob) + 1e-6\n",
    "    xtw = x.transpose() * w\n",
    "    xtwx = xtw.dot(x)\n",
    "    z = xbeta + (y - prob) / w\n",
    "    xtwz = xtw.dot(z)\n",
    "    objfn = -np.sum( y * (xbeta-softplus(xbeta) ) + (y-1) * softplus(xbeta) )\n",
    "    return xtwx, xtwz, objfn\n",
    "\n",
    "# iter computation\n",
    "\n",
    "p = data_partition_nonempty.first().shape[1]-1 #subtract y\n",
    "beta_hat = np.zeros(p)#initialization\n",
    "object_values = [] #init\n",
    "\n",
    "MaxIteration = 100 #iter settings\n",
    "epsilon = 1e-6 #iter settings\n",
    "\n",
    "for i in range(MaxIteration):\n",
    "    if (test):\n",
    "        print(f\"start iter:{i}\")\n",
    "    # 完整数据的 X'WX 和 X'Wz 是各分区的加和\n",
    "    xtwx, xtwz, objfn = data_partition_nonempty.\\\n",
    "        map(lambda part: compute_betahat(part, beta_hat)).\\\n",
    "        reduce(lambda x, y: (x[0] + y[0], x[1] + y[1], x[2] + y[2]))\n",
    "    # 计算新 beta\n",
    "    beta_new = np.linalg.solve(xtwx, xtwz)\n",
    "    if (test):\n",
    "        print(f\"bn{beta_new.shape}\")\n",
    "    # 计算 beta 的变化\n",
    "    resid = np.linalg.norm(beta_new - beta_hat)\n",
    "    print(f\"Iteration {i}, objfn = {objfn}, resid = {resid}\")\n",
    "    object_values.append(objfn)\n",
    "    # 如果 beta 几乎不再变化，退出循环\n",
    "    if resid < epsilon:\n",
    "        print(f\"Accomplish!\\nFinal Iteration {i}, objfn = {objfn}, resid = {resid}\")\n",
    "        break\n",
    "    # 更新 beta\n",
    "    beta_hat = beta_new"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 利用估计得到的 $\\hat{\\beta}$ 对原始数据进行预测，令 $\\hat{\\rho}_i$ 表示估计出的每个观测 $Y_i$ 取值为1的概率。为每个观测计算一个预测的0-1标签 $\\hat{l}_i$，规则如下：如果 $\\hat{\\rho}_i\\ge 0.5$，则 $\\hat{l}_i=1$，反之 $\\hat{l}_i=0$。利用分布式算法计算模型的预测准确度，即 $n^{-1}\\sum_{i=1}^n I(Y_i=\\hat{l}_i)$。$I(Y_i=\\hat{l}_i)$ 表示预测对取1，预测错取0。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.0856306   0.99734545  0.2829785  ...  0.37940061 -0.37917643  1.        ]\n",
      " [ 0.64205469 -1.97788793  0.71226464 ... -0.34126172 -0.21794626  1.        ]\n",
      " [ 0.70331012 -0.59810533  2.2007021  ...  0.16054442  0.81976061  1.        ]\n",
      " ...\n",
      " [ 0.14100959  0.80978972 -0.42440731 ...  2.24800309 -0.74050246  1.        ]\n",
      " [ 0.83784344 -0.61011528  1.25735545 ... -0.2700087  -1.25482477  1.        ]\n",
      " [ 0.34676545 -0.52206363 -0.04829659 ...  0.08482555  0.9228148   1.        ]]\n"
     ]
    }
   ],
   "source": [
    "one = np.ones((x.shape[0],1))\n",
    "X = np.hstack((x,one))\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:94.73700000000001%\n"
     ]
    }
   ],
   "source": [
    "probhat = sigmoid(X.dot(beta_hat))\n",
    "result = np.where(probhat>=0.5,1,0)\n",
    "if_right  = np.where(result ==y,1,0)\n",
    "right_num = sum(if_right)\n",
    "acc = right_num/len(result)\n",
    "print(f\"accuracy:{acc*100}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
