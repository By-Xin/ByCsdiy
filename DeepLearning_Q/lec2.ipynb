{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Sep.11, 2023***\n",
    "\n",
    "- 对于不确定性的度量才是统计学；不确定性就是数据的分布\n",
    "- 在统计学中，当我们知道了数据的分布，我们几乎就知道了一切\n",
    "- *Q：当在回归问题中，当假设误差服从t分布时，极大似然推导出的损失函数为？*\n",
    "- 交叉熵也是一种广义极大似然\n",
    "- Probit：二分类问题中的激活函数为正态分布的CDF\n",
    "- 超越极大似然？\n",
    "    - KL散度\n",
    "        - 为什么pq的选择？谁是真实谁是目标？\n",
    "        - min KL = MLE\n",
    "    - F散度/JS散度 …\n",
    "    \n",
    "    > 当使用不同的损失函数后，就可以推导出不同的深度学习模型\n",
    "\n",
    "- 许多机器学习的模型都是对于分布的刻画；而损失函数在某种意义上就是衡量***两个分布之间的区别***"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
