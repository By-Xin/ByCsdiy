{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a1368f0",
   "metadata": {},
   "source": [
    "# 卷积神经网络实践"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294a04c2",
   "metadata": {},
   "source": [
    "本次作业将练习卷积神经网络，利用卷积层和全连接层实现手写数字的识别。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ee659c",
   "metadata": {},
   "source": [
    "## 1. 目标"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997082ed",
   "metadata": {},
   "source": [
    "通过对 MNIST 数据进行训练，构建一个简单的图像分类模型，对图片中的数字进行识别。你将利用该模型对自己真实手写出的数字进行预测，观察模型效果。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0490f78e",
   "metadata": {},
   "source": [
    "## 2. 主要步骤"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b786836",
   "metadata": {},
   "source": [
    "1. 获取数据\n",
    "2. 定义模型结构\n",
    "3. 创建模型类\n",
    "4. 定义损失函数\n",
    "5. 编写训练循环\n",
    "6. 实施预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cd7d88",
   "metadata": {},
   "source": [
    "### 2.1 获取数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc63241",
   "metadata": {},
   "source": [
    "我们使用知名的 MNIST 数据集，它可以从 PyTorch 中利用工具函数下载得到。原始的 MNIST 数据训练集大小为60000，我们随机抽取其中的10000个观测进行简单的训练，以及10个观测进行预测展示。以下函数会在当前目录建立一个名为 data 的文件夹，其中会包含下载得到的数据集。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2069eef6",
   "metadata": {},
   "source": [
    "**注意：请在任何程序的最开始加上随机数种子的设置。请保持这一习惯。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57301cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "np.random.seed(123456)\n",
    "torch.manual_seed(123456)\n",
    "\n",
    "mnist = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "loader = DataLoader(mnist, batch_size=10010, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdaba44",
   "metadata": {},
   "source": [
    "我们一次性取出随机抽取到的10010个观测，其中 x 是图片数据，y 是图片对应的数字。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ae2977",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145971d1",
   "metadata": {},
   "source": [
    "一个习惯性动作是查看数据的大小和维度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67073f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbb19ee",
   "metadata": {},
   "source": [
    "将最后的10张图片取为测试集："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25db4998",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest = x[-10:]\n",
    "ytest = y[-10:]\n",
    "x = x[:-10]\n",
    "y = y[:-10]\n",
    "print(x.shape)\n",
    "print(xtest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a0aa24",
   "metadata": {},
   "source": [
    "我们可以利用下面的函数展示图片的内容。如选择第一张测试图片，先将其转换成 Numpy 数组，再绘制图形："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2de2307",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = xtest[0].squeeze().cpu().numpy()\n",
    "print(img.shape)\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0281c1d2",
   "metadata": {},
   "source": [
    "### 2.2 定义模型结构"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec06760",
   "metadata": {},
   "source": [
    "作为演示，我们创建一个卷积层、一个汇聚层和一个全连接层。所有隐藏层的函数细节都可以在[官方文档](https://pytorch.org/docs/stable/nn.html)中按分类找到。每一个隐藏层本质上都是将一个数组变换成另一个数组的函数，因此为了确认编写的模型是正确的，可以先用一个小数据进行测试，观察输入和输出的维度。例如，我们先取出前6个观测，此时输入的维度是 `[6, 1, 28, 28]`："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26ebf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = 6\n",
    "smallx = x[0:ns]\n",
    "smally = y[0:ns]\n",
    "print(smallx.shape)\n",
    "print(smally.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada326cb",
   "metadata": {},
   "source": [
    "接下来创建第1个卷积层，并测试输出的维度。注意到我们可以直接将隐藏层当成一个函数来调用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500c1874",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = torch.nn.Conv2d(in_channels=1, out_channels=20, kernel_size=5, stride=2)\n",
    "res1 = conv1(smallx)\n",
    "print(res1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e8230d",
   "metadata": {},
   "source": [
    "可以看到，输出的维度为 `[20, 12, 12]`（不包括第1位的数据批次维度）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc3c891",
   "metadata": {},
   "source": [
    "接下来我们创建一个最大汇聚层："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89164f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool1 = torch.nn.MaxPool2d(kernel_size=2)\n",
    "res2 = pool1(res1)\n",
    "print(res2.shape)\n",
    "assert res2.shape == (ns, 20, 6, 6), \"pool1 输出形状不对\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7dbe2b",
   "metadata": {},
   "source": [
    "可以看出此时的输出维度变成了 `[20, 6, 6]`。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789c8842",
   "metadata": {},
   "source": [
    "最后我们将得到的特征拉直，并输出10维的向量，用来计算每个类的概率预测："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb98fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输入：20 x 6 x 6 = 720\n",
    "# 输出：10\n",
    "fc1 = torch.nn.Linear(in_features=720, out_features=10)\n",
    "res3 = fc1(torch.flatten(res2, start_dim=1))\n",
    "print(res3.shape)\n",
    "assert res3.shape == (ns, 10), \"fc1 输出形状不对\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f623e96f",
   "metadata": {},
   "source": [
    "### 2.3 创建模型类"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ba53a4",
   "metadata": {},
   "source": [
    "在确保隐藏层维度都正确后，将所有的隐藏层封装到一个模型类中，其中模型结构在 `__init__()` 中定义，具体的计算过程在 `forward()` 中实现。此时需要加入激活函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6b79df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels=1, out_channels=20, kernel_size=5, stride=2)\n",
    "        self.pool1 = torch.nn.MaxPool2d(kernel_size=2)\n",
    "        self.fc1 = torch.nn.Linear(in_features=720, out_features=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = self.fc1(x)\n",
    "        x = torch.nn.functional.softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49894cba",
   "metadata": {},
   "source": [
    "再次测试输入输出的维度是否正确。如果模型编写正确，输出的维度应该是 `[6, 10]`，且输出结果为0到1之间的概率值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95558fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "torch.manual_seed(123)\n",
    "\n",
    "model = MyModel()\n",
    "pred = model(smallx)\n",
    "print(pred.shape)\n",
    "print()\n",
    "print(pred)\n",
    "print()\n",
    "print(torch.sum(pred, dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8236f0",
   "metadata": {},
   "source": [
    "`pred` 的每一行加总为1，其中每一个元素代表对应类别的预测概率。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca3a05a",
   "metadata": {},
   "source": [
    "我们还可以直接打印模型对象，观察隐藏层的结构："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a4eb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0bc12f",
   "metadata": {},
   "source": [
    "### 2.4 定义损失函数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd11e33",
   "metadata": {},
   "source": [
    "对于分类问题，损失函数通常选取为负对数似然函数。在 PyTorch 中，可以使用 `torch.nn.NLLLoss` 来完成计算。其用法是先定义一个损失函数对象，然后在预测值和真实标签上调用该函数对象。注意：损失函数对象的第一个参数是预测概率的**对数值**，第二个参数是真实的标签。[文档说明](https://pytorch.org/docs/stable/generated/torch.nn.NLLLoss.html)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4ee18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lossfn = torch.nn.NLLLoss()\n",
    "lossfn(torch.log(pred), smally)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf163e4",
   "metadata": {},
   "source": [
    "### 2.5 编写训练循环"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53f5d1a",
   "metadata": {},
   "source": [
    "利用课上介绍的循环模板和代码示例，对模型进行迭代训练。对于本数据，选取 mini-batch 大小为200，共遍历数据10遍，优化器选为 Adam，学习率为0.001。记录每个 mini-batch 下的损失函数值存放到列表 `losses_sgd` 中，然后画出损失函数的曲线。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99d1bb8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nepoch = 30\n",
    "batch_size = 200\n",
    "lr = 0.001\n",
    "\n",
    "np.random.seed(123)\n",
    "torch.manual_seed(123)\n",
    "\n",
    "model = MyModel()\n",
    "losses = []\n",
    "opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "n = x.shape[0]\n",
    "obs_id = np.arange(n)  # [0, 1, ..., n-1]\n",
    "# Run the whole data set `nepoch` times\n",
    "for i in range(nepoch):\n",
    "    # Shuffle observation IDs\n",
    "    np.random.shuffle(obs_id)\n",
    "\n",
    "    # Update on mini-batches\n",
    "    for j in range(0, n, batch_size):\n",
    "        # Create mini-batch\n",
    "        x_mini_batch = x[obs_id[j:(j + batch_size)]]\n",
    "        y_mini_batch = y[obs_id[j:(j + batch_size)]]\n",
    "        # Compute loss\n",
    "        pred = model(x_mini_batch)\n",
    "        lossfn = torch.nn.NLLLoss()\n",
    "        loss = lossfn(torch.log(pred), y_mini_batch)\n",
    "        # Compute gradient and update parameters\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        if (j // batch_size) % 20 == 0:\n",
    "            print(f\"epoch {i}, batch {j // batch_size}, loss = {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2d6346",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411e0bfe",
   "metadata": {},
   "source": [
    "### 2.6 实施预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc09b3f",
   "metadata": {},
   "source": [
    "为了验证模型的效果，我们对10个测试观测（即之前生成的 `testx`）进行预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a99a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = model(xtest)\n",
    "print(np.round(ypred.detach().cpu().numpy(), 3))\n",
    "print(ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c93ff3",
   "metadata": {},
   "source": [
    "如果模型搭建和训练都正常，那么每一行中概率最大的取值所在的位置应该正好对应真实的标签。我们也可以让 PyTorch 自动找到最大值的位置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bd7b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.argmax(ypred, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c34de42",
   "metadata": {},
   "source": [
    "最后，我们用模型对一些真实的手写数字图片进行预测。以下是一个例子：\n",
    "![](digits/sample2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35066889",
   "metadata": {},
   "source": [
    "接下来利用 Pillow 软件包读取图片："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d19fbd2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "im = Image.open(\"digits/sample2.png\")\n",
    "im"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f30128c",
   "metadata": {},
   "source": [
    "此时如果直接将其转为 Numpy 数组会得到三个通道："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3999832",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_arr = np.array(im)\n",
    "print(im_arr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d85450",
   "metadata": {},
   "source": [
    "因此，我们先强制转换为灰度图片（单通道），再缩放至模型的图片大小 28 x 28："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102618e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "im = im.convert(\"L\")\n",
    "im.thumbnail((28, 28))\n",
    "im_arr = np.array(im)\n",
    "print(im_arr.shape)\n",
    "im"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3978a9d6",
   "metadata": {},
   "source": [
    "为了传递给模型对象，还需要先将数值归一化到 [0,1] 区间，转换为 PyTorch 的 Tensor 类型，并增加一个批次和一个通道的维度："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6af013",
   "metadata": {},
   "outputs": [],
   "source": [
    "test0 = torch.tensor(im_arr / 255.0, dtype=torch.float32).view(1, 1, 28, 28)\n",
    "print(test0.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69402359",
   "metadata": {},
   "source": [
    "最后对图片标签进行预测："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b1f088",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred0 = model(test0)\n",
    "print(np.round(pred0.detach().cpu().numpy(), 3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
