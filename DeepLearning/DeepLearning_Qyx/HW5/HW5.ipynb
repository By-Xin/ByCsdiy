{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a1368f0",
   "metadata": {},
   "source": [
    "# 作业5：RNN 生成模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997082ed",
   "metadata": {},
   "source": [
    "以 `data/names.txt` 中的英文名作为训练集，利用 RNN 或 LSTM 等方法对字母序列数据进行建模，然后使用拟合的模型随机生成20个名字。本次作业为开放式，不指定各类超参数（如网络结构、学习率、迭代次数等），但需提供必要的输出和诊断结果支持你的选择（如模型是否收敛、效果评价等）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b11e45",
   "metadata": {},
   "source": [
    "提示：可以参照 `lec12-rnn-generation.zip` 中的代码，但注意英文名不需要像中文那样构建字典，因为可以直接使用26个字母作为字典。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T13:42:12.414388200Z",
     "start_time": "2023-12-03T13:42:12.409841900Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import itertools\n",
    "import collections\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T13:42:14.027362Z",
     "start_time": "2023-12-03T13:42:14.019397800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abbas', 'abbey', 'abbott', 'abdi', 'abel']\n"
     ]
    }
   ],
   "source": [
    "# load txt file\n",
    "\n",
    "def read_txt_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        content = file.read().split()\n",
    "        return content\n",
    "\n",
    "dat = read_txt_file('data/names.txt')\n",
    "print(dat[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T13:42:15.588186400Z",
     "start_time": "2023-12-03T13:42:15.581103800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '<EOS>']\n"
     ]
    }
   ],
   "source": [
    "# construct dictionary\n",
    "charset_size = 27 # 26 letters  + 1 <EOS>\n",
    "dictionary = list('abcdefghijklmnopqrstuvwxyz') + ['<EOS>'] \n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]),\n",
       " array([4, 6]),\n",
       " tensor([[ 4,  0],\n",
       "         [14,  2],\n",
       "         [13,  7],\n",
       "         [26,  4],\n",
       "         [26, 11],\n",
       "         [26, 26]]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# names to tensor\n",
    "def char2index(char):\n",
    "    \"\"\"Transform a character to its index in the dictionary\n",
    "    Args:\n",
    "        char (str): a character\n",
    "        \n",
    "    Returns:\n",
    "       int: the index of the character in the dictionary\n",
    "        \n",
    "    \"\"\"\n",
    "    return dictionary.index(char.lower()) \n",
    "\n",
    "def names2tensor(NameList):\n",
    "    \"\"\"Transform a list of names to one-hot tensor\n",
    "    Args:\n",
    "        NameList (array): a list of names\n",
    "        \n",
    "    Returns:\n",
    "        tensor: a tensor of shape (LongestNameLength, NumberOfNames, charset_size=27), storing the one-hot representation of names\n",
    "        array: a numpy array of shape (NumberOfNames), storing each name's length\n",
    "        target: a tensor of shape (LongestNameLength, NumberOfNames), storing the index of the next letter\n",
    "        \n",
    "    \"\"\"\n",
    "    names_num = len(NameList) # number of names\n",
    "    names_lens = [len(name) for name in NameList] # a list storing each name's length\n",
    "    max_name_len = max(names_lens) # the longest name's length\n",
    "    \n",
    "    tensor = torch.zeros(max_name_len, names_num, charset_size) # (each char in a name, each name, one-hot vector)\n",
    "    target = torch.zeros(max_name_len, names_num, dtype=int) + charset_size - 1 # initialize with <EOS>\n",
    "    \n",
    "    for name_i in range(names_num): # for each name(idx) in data set\n",
    "        name = NameList[name_i] # get the name\n",
    "        for char_i in range(names_lens[name_i]): # for each char(idx) in the name\n",
    "            # set tensor\n",
    "            tensor[char_i, name_i, char2index(name[char_i])] = 1 # set the corresponding one-hot vector\n",
    "            # set target\n",
    "            if char_i < names_lens[name_i] - 1: # if not the last char (here note that python index starts from 0)\n",
    "                target[char_i, name_i] = char2index(name[char_i + 1]) # target for name_i, char_i is char_i+1\n",
    "                \n",
    "    return tensor, np.array(names_lens), target\n",
    "\n",
    "# test names2tensor\n",
    "names2tensor([\"leon\",\"rachel\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
