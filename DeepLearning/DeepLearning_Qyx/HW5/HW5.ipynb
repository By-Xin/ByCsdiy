{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a1368f0",
   "metadata": {},
   "source": [
    "# 作业5：RNN 生成模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997082ed",
   "metadata": {},
   "source": [
    "以 `data/names.txt` 中的英文名作为训练集，利用 RNN 或 LSTM 等方法对字母序列数据进行建模，然后使用拟合的模型随机生成20个名字。本次作业为开放式，不指定各类超参数（如网络结构、学习率、迭代次数等），但需提供必要的输出和诊断结果支持你的选择（如模型是否收敛、效果评价等）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b11e45",
   "metadata": {},
   "source": [
    "提示：可以参照 `lec12-rnn-generation.zip` 中的代码，但注意英文名不需要像中文那样构建字典，因为可以直接使用26个字母作为字典。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T11:42:04.645497700Z",
     "start_time": "2023-12-04T11:42:00.191807700Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import itertools\n",
    "import collections\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 处理数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T11:42:08.783637Z",
     "start_time": "2023-12-04T11:42:08.623557100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abbas', 'abbey', 'abbott', 'abdi', 'abel']\n"
     ]
    }
   ],
   "source": [
    "# load txt file\n",
    "\n",
    "def read_txt_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        content = file.read().split()\n",
    "        return content\n",
    "\n",
    "dat = read_txt_file('data/names.txt')\n",
    "print(dat[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T11:42:23.907980700Z",
     "start_time": "2023-12-04T11:42:23.892846700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '<EOS>']\n"
     ]
    }
   ],
   "source": [
    "# construct dictionary\n",
    "charset_size = 27 # 26 letters  + 1 <EOS>\n",
    "dictionary = list('abcdefghijklmnopqrstuvwxyz') + ['<EOS>'] \n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T11:42:26.701001Z",
     "start_time": "2023-12-04T11:42:26.639429500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "           0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]),\n",
       " array([4, 6]),\n",
       " tensor([[ 4,  0],\n",
       "         [14,  2],\n",
       "         [13,  7],\n",
       "         [26,  4],\n",
       "         [26, 11],\n",
       "         [26, 26]]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# names to tensor\n",
    "def char2index(char):\n",
    "    \"\"\"Transform a character to its index in the dictionary\n",
    "    Args:\n",
    "        char (str): a character\n",
    "        \n",
    "    Returns:\n",
    "       int: the index of the character in the dictionary\n",
    "        \n",
    "    \"\"\"\n",
    "    return dictionary.index(char.lower()) \n",
    "\n",
    "def names2tensor(NameList):\n",
    "    \"\"\"Transform a list of names to one-hot tensor\n",
    "    Args:\n",
    "        NameList (array): a list of names\n",
    "        \n",
    "    Returns:\n",
    "        tensor: a tensor of shape (LongestNameLength, NumberOfNames, charset_size=27), storing the one-hot representation of names\n",
    "        array: a numpy array of shape (NumberOfNames), storing each name's length\n",
    "        target: a tensor of shape (LongestNameLength, NumberOfNames), storing the index of the next letter\n",
    "        \n",
    "    \"\"\"\n",
    "    names_num = len(NameList) # number of names\n",
    "    names_lens = [len(name) for name in NameList] # a list storing each name's length\n",
    "    max_name_len = max(names_lens) # the longest name's length\n",
    "    \n",
    "    tensor = torch.zeros(max_name_len, names_num, charset_size) # (each char in a name, each name, one-hot vector)\n",
    "    target = torch.zeros(max_name_len, names_num, dtype=int) + charset_size - 1 # initialize with <EOS>\n",
    "    \n",
    "    for name_i in range(names_num): # for each name(idx) in data set\n",
    "        name = NameList[name_i] # get the name\n",
    "        for char_i in range(names_lens[name_i]): # for each char(idx) in the name\n",
    "            # set tensor\n",
    "            tensor[char_i, name_i, char2index(name[char_i])] = 1 # set the corresponding one-hot vector\n",
    "            # set target\n",
    "            if char_i < names_lens[name_i] - 1: # if not the last char (here note that python index starts from 0)\n",
    "                target[char_i, name_i] = char2index(name[char_i + 1]) # target for name_i, char_i is char_i+1\n",
    "                \n",
    "    return tensor, np.array(names_lens), target\n",
    "\n",
    "# test names2tensor\n",
    "names2tensor([\"leon\",\"rachel\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 构建LSTM模型类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![](https://michael-1313341240.cos.ap-shanghai.myqcloud.com/202312042025464.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters Definition:\n",
    "\n",
    "- Suppose there are $h$ hidden units, batch size is $n$, number of inputs is $d$. Thus, $X_t \\in \\mathbb{R}^{n\\times h}, H_t = \\mathbb{R}^{n\\times h}.$\n",
    "- Define Gates (at time $t$):\n",
    "    - Input gate ($I_t \\in \\mathbb{R}^{n\\times h}$) : $I_t = \\text{sigmoid}(X_t W_{xi} + H_{t-1} W_{hi} + b_i)$\n",
    "    - Forget gate ($F_t \\in \\mathbb{R}^{n\\times h}$) : $F_t = \\text{sigmoid}({X_t W_{xf} + H_{t-1} W_{hf} + b_f)}$\n",
    "    - Output gate ($O_t \\in  \\mathbb{R}^{n\\times h}$) : $O_t = \\text{sigmoid}{X_t W_{xo} + H_{t-1} W_{ho} + b_o)}$\n",
    "  \n",
    "  where $W_{x,\\cdot} \\in \\mathbb{R}^{d\\times h}$, $W_{h,\\cdot} \\in \\mathbb{R}^{h\\times h}$, $b_{\\cdot} \\in \\mathbb{R}^{1\\times h}$.\n",
    "\n",
    "- Define Candidate Memory Cell $\\tilde C$:\n",
    "\n",
    "$$\n",
    "  \\tilde C_t = \\text{tanh}(X_t W_{xc} + H_{t-1} W_{hc} + b_c)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "> *Reference*\n",
    ">\n",
    "> *1. Dive Into Deep Learning (https://zh.d2l.ai/chapter_recurrent-modern/lstm.html)*\n",
    ">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LSTM\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(LSTM,self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size #?\n",
    "        \n",
    "        self.X2F = nn.Linear(in_features = input_size + hidden_size,\n",
    "                             out_features = hidden_size )\n",
    "        self.X2I = nn.Linear(in_features = input_size + hidden_size,\n",
    "                             out_features = hidden_size )\n",
    "        self.X2O = nn.Linear(in_features = input_size + hidden_size,\n",
    "                             out_features = hidden_size )\n",
    "        \n",
    "        self.X2Ct = nn.Linear(in_features = input_size + hidden_size,\n",
    "                             out_features = hidden_size )\n",
    "        \n",
    "        self.O2O = nn.Linear(in_features = hidden_size,\n",
    "                             out_features = hidden_size)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, input, hidden, MemCell):\n",
    "        \n",
    "        input_combined = torch.cat((input,hidden),1)     #? how\n",
    "        \n",
    "        ForgetGate = torch.sigmoid(self.X2F(input_combined))   \n",
    "        InputGate = torch.sigmoid(self.X2I(input_combined))\n",
    "        OutputGate = torch.sigmoid(self.X2O(input_combined))\n",
    "        \n",
    "        CandidateMemCell = torch.tanh(self.X2Ct(input_combined))\n",
    "        \n",
    "        MemCell = ForgetGate * MemCell + InputGate * CandidateMemCell\n",
    "        \n",
    "        hidden = OutputGate * torch.tanh(MemCell)\n",
    "        print(f\"hidden:{hidden.shape}\")\n",
    "        \n",
    "        output = self.O2O(hidden)\n",
    "        output = self.dropout(output)\n",
    "        output = self.logsoftmax(output)\n",
    "        \n",
    "        return output, hidden, MemCell\n",
    "    \n",
    "    def init_hidden(self, batch_size, device):\n",
    "        return torch.zeros((batch_size, self.hidden_size), device = device)\n",
    "\n",
    "    def init_MemCell(self, batch_size, device):\n",
    "        return torch.zeros((batch_size, self.hidden_size), device = device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden = 64\n",
    "lstm = LSTM(charset_size, n_hidden)\n",
    "def name2tensor(name):\n",
    "    \"\"\"将名字转换为 one-hot 编码的张量\"\"\"\n",
    "    tensor = torch.zeros(len(name), 1, charset_size) #一个tensor（其实是2d矩阵的感觉），第一个维度是名字的长度（名字中的各个字符），第二个维度是1，第三个维度是每个字符的onehot\n",
    "    for i, char in enumerate(name): #enmuerate\n",
    "        tensor[i, 0, char2index(char)] = 1\n",
    "    return tensor\n",
    "\n",
    "input = name2tensor(\"leon\")\n",
    "hidden = lstm.init_hidden(batch_size=1, device='cpu')\n",
    "MemCell = lstm.init_MemCell(batch_size=1, device='cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\xinby\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\xinby\\AppData\\Local\\Temp\\ipykernel_18768\\1103372874.py\", line 1, in <module>\n",
      "    output, next_hidden = lstm(input[0], hidden, MemCell)\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\xinby\\.conda\\envs\\win_DL_Q\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\xinby\\AppData\\Local\\Temp\\ipykernel_18768\\3351133768.py\", line 38, in forward\n",
      "    output = self.O2O(hidden)\n",
      "             ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\xinby\\.conda\\envs\\win_DL_Q\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\xinby\\.conda\\envs\\win_DL_Q\\Lib\\site-packages\\torch\\nn\\modules\\linear.py\", line 114, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: mat1 and mat2 shapes cannot be multiplied (1x64 and 91x64)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\xinby\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 2105, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\xinby\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\ultratb.py\", line 1396, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\xinby\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\ultratb.py\", line 1287, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\xinby\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\ultratb.py\", line 1140, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\xinby\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\ultratb.py\", line 1055, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\xinby\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\ultratb.py\", line 955, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\xinby\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\ultratb.py\", line 778, in lines\n",
      "    return self._sd.lines\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\xinby\\AppData\\Roaming\\Python\\Python311\\site-packages\\stack_data\\utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\xinby\\AppData\\Roaming\\Python\\Python311\\site-packages\\stack_data\\core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\xinby\\AppData\\Roaming\\Python\\Python311\\site-packages\\stack_data\\utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\xinby\\AppData\\Roaming\\Python\\Python311\\site-packages\\stack_data\\core.py\", line 677, in included_pieces\n",
      "    scope_pieces = self.scope_pieces\n",
      "                   ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\xinby\\AppData\\Roaming\\Python\\Python311\\site-packages\\stack_data\\utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\xinby\\AppData\\Roaming\\Python\\Python311\\site-packages\\stack_data\\core.py\", line 614, in scope_pieces\n",
      "    scope_start, scope_end = self.source.line_range(self.scope)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\xinby\\AppData\\Roaming\\Python\\Python311\\site-packages\\stack_data\\core.py\", line 178, in line_range\n",
      "    return line_range(self.asttext(), node)\n",
      "                      ^^^^^^^^^^^^\n",
      "AttributeError: 'Source' object has no attribute 'asttext'\n"
     ]
    }
   ],
   "source": [
    "output, next_hidden = lstm(input[0], hidden, MemCell)\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
