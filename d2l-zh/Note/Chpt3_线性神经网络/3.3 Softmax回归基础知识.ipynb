{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 分类问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- one-hot encoding\n",
    "- 在本节中，考虑这样一个图像分类问题：假设每次输入都是一个2*2的灰度图像，对应四个特征$x_1, x_2, x_3, x_4$，类别为$y\\in \\{(1,0,0),(0,1,0),(0,0,1)\\}$之一。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 网络架构"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 为了解决分类问题，最终输出层的节点数应与类别数相同，这里为3；每个输出节点对应一个自己的仿射函数。\n",
    "- 在本例中，输入层的特征数为4，输出层的节点数为3，因此权重矩阵$W$的形状为$4\\times 3$，偏置向量$b$的长度为3。\n",
    "\n",
    "可以初步将预测规则定义为：\n",
    "$$\n",
    "\\begin{aligned}\n",
    "& o_1=x_1 w_{11}+x_2 w_{12}+x_3 w_{13}+x_4 w_{14}+b_1 \\\\\n",
    "& o_2=x_1 w_{21}+x_2 w_{22}+x_3 w_{23}+x_4 w_{24}+b_2 \\\\\n",
    "& o_3=x_1 w_{31}+x_2 w_{32}+x_3 w_{33}+x_4 w_{34}+b_3\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "可以知道，和线性回归一样，softmax回归也是一个单层神经网络。由于计算每个输出$o_1,o_2,o_3$取决于所有输入$x_1,x_2,x_3,x_4$，softmax回归的输出层也是一个全连接层。\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://michael-1313341240.cos.ap-shanghai.myqcloud.com/202309110938436.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally可以写作：\n",
    "$$\\bold{o} =  \\bold{W} \\bold{x}+ \\bold{b}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 参数开销（计算复杂度）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Theoretically，具有$d$个输入和$q$个输出的全连接层的开销为$\\mathcal{O}(dq)$\n",
    "- 将$d$个输入转换为$q$个输出的成本可以减少到$\\mathcal{O}(dq/n)$ \n",
    "  > *(Zhang, A., Tay, Y., Zhang, S., Chan, A., Luu, A. T., Hui, S. C., & Fu, J. (2021). Beyond fully-connected layers with quaternions: parameterization of hypercomplex multiplications with 1/n parameters. International Conference on Learning Representations.)*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "引入Softmax公式：\n",
    "$$\n",
    "\\bold{\\hat y} = \\text{softmax}(\\bold{o}) \\quad \\text{where} \\quad \\hat y_j = \\frac{\\exp(o_j)}{\\sum_k \\exp(o_k)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "尽管Softmax是一个非线性的函数，但是softmax回归的输出仍然由输入特征的仿射变换决定。 因此，softmax回归是一个线性模型（linear model）。"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
