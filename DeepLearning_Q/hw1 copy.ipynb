{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 作业1：问卷+环境配置"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. 说明"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1 关于 Jupyter Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jupyter Notebook 是一种可编程的文档类型，类似于 R Markdown。Jupyter Notebook 文档以一个个单元格组成，每个单元格可以是 Markdown 或者 Python 代码：前者通常用来写文字说明，后者用来运行代码。比如你双击第一行的标题，就会看到标题的 Markdown 代码（以 `#` 符号开头），再按 `Ctrl+Enter`，就会显示 Markdown 渲染的结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "而对于代码单元格， `Ctrl+Enter` 会执行单元格内的代码，例如用鼠标点击下面的单元格然后按键后会出现形如 `Out[x]` 的输出结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.141592653589793"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "math.pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们的作业中既有需要说明的文字，又有需要编写的程序，前者用 Markdown 单元格，后者用代码单元格。单元格的类型可以在上方的下拉菜单中选择，也可以通过快捷键实现（通过菜单 Cell => Cell Type 查看）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2 关于 Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Markdown 是常用的文档格式化语法，如果有不熟悉的，可以参考[这里](https://www.jianshu.com/p/335db5716248)的教程。需要说明的是 Jupyter Notebook 里可以插入数学公式，例如 $f(x)=\\frac{1}{\\sqrt{2\\pi}}e^{-x^2/2}$。双击这个单元格来查看源代码。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 问卷"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "思考并回答**至少四个**问题："
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **你现在对深度学习有多少了解？**\n",
    "\n",
    "    跟着Seminar、各路大神大佬（李沐、李宏毅、Andrew Ng），还有暑假的兴趣小组学长姐们已经听过好多讲座、报告之类，基础的像CNN,RNN等等，最近的Attention，Transformer，BERT，但是都是在理论层面，没有实际操作过（就很悲伤），而且感觉也不成体系（更悲伤了）"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **你预期今后的工作/研究与深度学习的关联大吗？**\n",
    "\n",
    "    希望可以很大（）。想做NLP，往下读PhD这样，所以希望能够和深度学习一直相爱相杀下去。而且就算以后不幸（或者是有幸？）去到业界工作，也希望能够从事与之相关的一些内容（比如算法开发？或者在一些互联网/金融厂利用深度学习继续开展业务）"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **你想从这门课学到什么？**\n",
    "\n",
    "    前面有说嘛，在选这门课的时候主要的预期在于：\n",
    "\n",
    "    1. 更系统的了解深度学习这个领域，有一个自己较为清晰的脉络理解（明白一学期短短的16次课肯定没办法面面俱到，但是至少希望能够对这个领域能初见其貌，先“把地图跑开”，在日后不论是研究生还是自学上，都能有一个相对清晰一点的认识）；\n",
    "        \n",
    "    2. 希望能够具体实现一些（哪怕是demo）也好的深度学习模型，去大量的进行coding（不是那种纯粹封装好调包那种）。在为数不多的理解一直在听各路神仙们非常炫酷的讲解，但是对于具体的编程实现知之甚少。希望自己能够从零开始完整搭建一个这样的神经网络。\n",
    "\n",
    "  但是在上完两次课之后，似乎还有了新的期待：\n",
    "  \n",
    "  希望能够得到更深的关于统计学的认识。比如第二次课讲授的关于**分布**的这个内容就很有启发（邱、、不愧是你、、颇有醍醐灌顶之感）。确实，想来的话，确实希望这门深度学习的课，不是一门信息学院计算机系的”深度学习“，而是作为一个设立在统计与管理学院下面的”深度学习“。自己虽然前面也有说很希望能够有大量的编程实践，但是coding可能更多的是对于这门”课程“的一个期待。而这些统计学，或者是更宏观的方法论上的这些内容，却倒确实是更对于每周一上午10.05～11.45的“课堂”的一个期待～"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 你还有哪些喜欢的获取知识的渠道（例如B站，知乎，技术博客，公众号等）？如果有请向大家推荐一些，**具体到账号或网址**，不需要与深度学习相关。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **你对编程的喜欢/厌恶程度是多少？1为很厌恶，10为很喜欢。**\n",
    "  $$ 10 \\times \\textit1_{\\text{\\{No Bug\\}}} $$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **你喜欢/**不**喜欢的上课方式是怎样的？**\n",
    "\n",
    "    喜欢大家一起有效互动，像一个community一样互相提出好问题，解答好问题（当然，所有问题，除了水发言的问题，都是好问题）。课程除了coding也有很多对于统计学本身更高屋建瓴的理解（而不是只学会几个函数，调用一些包）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 安装 PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请参照课程文档《PyTorch安装》的提示配置好 PyTorch 环境。如果你的电脑具备 Nvidia 显卡，优先尝试安装 GPU 版本。用如下的代码验证 Conda 和 PyTorch 安装是否成功："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "     active environment : deepL_Q\n",
      "    active env location : /Users/xinby/opt/anaconda3/envs/deepL_Q\n",
      "            shell level : 2\n",
      "       user config file : /Users/xinby/.condarc\n",
      " populated config files : /Users/xinby/.condarc\n",
      "          conda version : 23.3.1\n",
      "    conda-build version : 3.21.8\n",
      "         python version : 3.9.12.final.0\n",
      "       virtual packages : __archspec=1=x86_64\n",
      "                          __osx=10.16=0\n",
      "                          __unix=0=0\n",
      "       base environment : /Users/xinby/opt/anaconda3  (writable)\n",
      "      conda av data dir : /Users/xinby/opt/anaconda3/etc/conda\n",
      "  conda av metadata url : None\n",
      "           channel URLs : https://mirrors.sustech.edu.cn/anaconda/pkgs/main/osx-64\n",
      "                          https://mirrors.sustech.edu.cn/anaconda/pkgs/main/noarch\n",
      "                          https://mirrors.sustech.edu.cn/anaconda/pkgs/free/osx-64\n",
      "                          https://mirrors.sustech.edu.cn/anaconda/pkgs/free/noarch\n",
      "                          https://mirrors.sustech.edu.cn/anaconda/cloud/pytorch/osx-64\n",
      "                          https://mirrors.sustech.edu.cn/anaconda/cloud/pytorch/noarch\n",
      "                          https://mirrors.sustech.edu.cn/anaconda-extra/cloud/nvidia/osx-64\n",
      "                          https://mirrors.sustech.edu.cn/anaconda-extra/cloud/nvidia/noarch\n",
      "                          https://mirrors.sustech.edu.cn/anaconda/cloud/conda-forge/osx-64\n",
      "                          https://mirrors.sustech.edu.cn/anaconda/cloud/conda-forge/noarch\n",
      "          package cache : /Users/xinby/opt/anaconda3/pkgs\n",
      "                          /Users/xinby/.conda/pkgs\n",
      "       envs directories : /Users/xinby/opt/anaconda3/envs\n",
      "                          /Users/xinby/.conda/envs\n",
      "               platform : osx-64\n",
      "             user-agent : conda/23.3.1 requests/2.27.1 CPython/3.9.12 Darwin/22.5.0 OSX/10.16\n",
      "                UID:GID : 501:20\n",
      "             netrc file : None\n",
      "           offline mode : False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1115,  0.1204, -0.3696],\n",
       "        [-0.2404, -1.1969,  0.2093],\n",
       "        [-0.9724, -0.7550,  0.3239],\n",
       "        [-0.1085,  0.2103, -0.3908],\n",
       "        [ 0.2350,  0.6653,  0.3528]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(123)\n",
    "torch.randn(5, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Diffusion Model（选做）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "按照 `lec1-huggingface.ipynb` 的提示配置好 Hugging Face 环境，并运行一个 Stable Diffusion 文生图的例子。发挥你的创意选择 Prompt 提示词，并在硬件条件允许的情况下适当增加 `num_inference_steps` 参数以提升生成质量。如果模型下载过慢，可以从实验室机房的电脑中复制模型文件，路径为 `C:\\Users\\<用户名>\\.cache\\huggingface`。将此文件夹复制到你自己电脑的对应位置（Windows 下为你用户名的对应文件夹，Mac/Linux 下为 `~/.cache/huggingface`。）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f37780ab6c0a4f7ca889416e266b070a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 15 files:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4da0bcaea2dd4f5f9c1208ea7060d1a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ch_model.safetensors:   0%|          | 0.00/335M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3067bd5fb7e469c856fdf02f5ece3ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71c494ecfbb949b0960bed1e267676b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/492M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d6a28d07b8e44329dca2a6d27538f98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ch_model.safetensors:   0%|          | 0.00/3.44G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/xinby/Desktop/ByCsdiy/DeepLearning_Q/hw1 copy.ipynb Cell 26\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/xinby/Desktop/ByCsdiy/DeepLearning_Q/hw1%20copy.ipynb#X34sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/xinby/Desktop/ByCsdiy/DeepLearning_Q/hw1%20copy.ipynb#X34sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdiffusers\u001b[39;00m \u001b[39mimport\u001b[39;00m StableDiffusionPipeline\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/xinby/Desktop/ByCsdiy/DeepLearning_Q/hw1%20copy.ipynb#X34sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m pipe \u001b[39m=\u001b[39m StableDiffusionPipeline\u001b[39m.\u001b[39mfrom_pretrained(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/xinby/Desktop/ByCsdiy/DeepLearning_Q/hw1%20copy.ipynb#X34sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mrunwayml/stable-diffusion-v1-5\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/xinby/Desktop/ByCsdiy/DeepLearning_Q/hw1%20copy.ipynb#X34sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     torch_dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat16\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/xinby/Desktop/ByCsdiy/DeepLearning_Q/hw1%20copy.ipynb#X34sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m )\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/xinby/Desktop/ByCsdiy/DeepLearning_Q/hw1%20copy.ipynb#X34sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m pipe\u001b[39m.\u001b[39mto(\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/xinby/Desktop/ByCsdiy/DeepLearning_Q/hw1%20copy.ipynb#X34sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m prompt \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mPiano by the sea\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/deepL_Q/lib/python3.11/site-packages/diffusers/pipelines/pipeline_utils.py:882\u001b[0m, in \u001b[0;36mDiffusionPipeline.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[39m# 1. Download the checkpoints and configs\u001b[39;00m\n\u001b[1;32m    880\u001b[0m \u001b[39m# use snapshot download here to get it working from from_pretrained\u001b[39;00m\n\u001b[1;32m    881\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misdir(pretrained_model_name_or_path):\n\u001b[0;32m--> 882\u001b[0m     cached_folder \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mdownload(\n\u001b[1;32m    883\u001b[0m         pretrained_model_name_or_path,\n\u001b[1;32m    884\u001b[0m         cache_dir\u001b[39m=\u001b[39mcache_dir,\n\u001b[1;32m    885\u001b[0m         resume_download\u001b[39m=\u001b[39mresume_download,\n\u001b[1;32m    886\u001b[0m         force_download\u001b[39m=\u001b[39mforce_download,\n\u001b[1;32m    887\u001b[0m         proxies\u001b[39m=\u001b[39mproxies,\n\u001b[1;32m    888\u001b[0m         local_files_only\u001b[39m=\u001b[39mlocal_files_only,\n\u001b[1;32m    889\u001b[0m         use_auth_token\u001b[39m=\u001b[39muse_auth_token,\n\u001b[1;32m    890\u001b[0m         revision\u001b[39m=\u001b[39mrevision,\n\u001b[1;32m    891\u001b[0m         from_flax\u001b[39m=\u001b[39mfrom_flax,\n\u001b[1;32m    892\u001b[0m         use_safetensors\u001b[39m=\u001b[39muse_safetensors,\n\u001b[1;32m    893\u001b[0m         custom_pipeline\u001b[39m=\u001b[39mcustom_pipeline,\n\u001b[1;32m    894\u001b[0m         custom_revision\u001b[39m=\u001b[39mcustom_revision,\n\u001b[1;32m    895\u001b[0m         variant\u001b[39m=\u001b[39mvariant,\n\u001b[1;32m    896\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    897\u001b[0m     )\n\u001b[1;32m    898\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    899\u001b[0m     cached_folder \u001b[39m=\u001b[39m pretrained_model_name_or_path\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/deepL_Q/lib/python3.11/site-packages/diffusers/pipelines/pipeline_utils.py:1324\u001b[0m, in \u001b[0;36mDiffusionPipeline.download\u001b[0;34m(cls, pretrained_model_name, **kwargs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m     user_agent[\u001b[39m\"\u001b[39m\u001b[39mcustom_pipeline\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m custom_pipeline\n\u001b[1;32m   1323\u001b[0m \u001b[39m# download all allow_patterns - ignore_patterns\u001b[39;00m\n\u001b[0;32m-> 1324\u001b[0m cached_folder \u001b[39m=\u001b[39m snapshot_download(\n\u001b[1;32m   1325\u001b[0m     pretrained_model_name,\n\u001b[1;32m   1326\u001b[0m     cache_dir\u001b[39m=\u001b[39mcache_dir,\n\u001b[1;32m   1327\u001b[0m     resume_download\u001b[39m=\u001b[39mresume_download,\n\u001b[1;32m   1328\u001b[0m     proxies\u001b[39m=\u001b[39mproxies,\n\u001b[1;32m   1329\u001b[0m     local_files_only\u001b[39m=\u001b[39mlocal_files_only,\n\u001b[1;32m   1330\u001b[0m     use_auth_token\u001b[39m=\u001b[39muse_auth_token,\n\u001b[1;32m   1331\u001b[0m     revision\u001b[39m=\u001b[39mrevision,\n\u001b[1;32m   1332\u001b[0m     allow_patterns\u001b[39m=\u001b[39mallow_patterns,\n\u001b[1;32m   1333\u001b[0m     ignore_patterns\u001b[39m=\u001b[39mignore_patterns,\n\u001b[1;32m   1334\u001b[0m     user_agent\u001b[39m=\u001b[39muser_agent,\n\u001b[1;32m   1335\u001b[0m )\n\u001b[1;32m   1337\u001b[0m \u001b[39mreturn\u001b[39;00m cached_folder\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/deepL_Q/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    116\u001b[0m     kwargs \u001b[39m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[39m=\u001b[39mfn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, has_token\u001b[39m=\u001b[39mhas_token, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[0;32m--> 118\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/deepL_Q/lib/python3.11/site-packages/huggingface_hub/_snapshot_download.py:235\u001b[0m, in \u001b[0;36msnapshot_download\u001b[0;34m(repo_id, revision, repo_type, cache_dir, local_dir, local_dir_use_symlinks, library_name, library_version, user_agent, proxies, etag_timeout, resume_download, force_download, token, local_files_only, allow_patterns, ignore_patterns, max_workers, tqdm_class)\u001b[0m\n\u001b[1;32m    233\u001b[0m         _inner_hf_hub_download(file)\n\u001b[1;32m    234\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 235\u001b[0m     thread_map(\n\u001b[1;32m    236\u001b[0m         _inner_hf_hub_download,\n\u001b[1;32m    237\u001b[0m         filtered_repo_files,\n\u001b[1;32m    238\u001b[0m         desc\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFetching \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(filtered_repo_files)\u001b[39m}\u001b[39;00m\u001b[39m files\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    239\u001b[0m         max_workers\u001b[39m=\u001b[39mmax_workers,\n\u001b[1;32m    240\u001b[0m         \u001b[39m# User can use its own tqdm class or the default one from `huggingface_hub.utils`\u001b[39;00m\n\u001b[1;32m    241\u001b[0m         tqdm_class\u001b[39m=\u001b[39mtqdm_class \u001b[39mor\u001b[39;00m hf_tqdm,\n\u001b[1;32m    242\u001b[0m     )\n\u001b[1;32m    244\u001b[0m \u001b[39mif\u001b[39;00m local_dir \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    245\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mstr\u001b[39m(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mrealpath(local_dir))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/deepL_Q/lib/python3.11/site-packages/tqdm/contrib/concurrent.py:69\u001b[0m, in \u001b[0;36mthread_map\u001b[0;34m(fn, *iterables, **tqdm_kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[39mEquivalent of `list(map(fn, *iterables))`\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39mdriven by `concurrent.futures.ThreadPoolExecutor`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[39m    [default: max(32, cpu_count() + 4)].\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mconcurrent\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfutures\u001b[39;00m \u001b[39mimport\u001b[39;00m ThreadPoolExecutor\n\u001b[0;32m---> 69\u001b[0m \u001b[39mreturn\u001b[39;00m _executor_map(ThreadPoolExecutor, fn, \u001b[39m*\u001b[39miterables, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtqdm_kwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/deepL_Q/lib/python3.11/site-packages/tqdm/contrib/concurrent.py:51\u001b[0m, in \u001b[0;36m_executor_map\u001b[0;34m(PoolExecutor, fn, *iterables, **tqdm_kwargs)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mwith\u001b[39;00m ensure_lock(tqdm_class, lock_name\u001b[39m=\u001b[39mlock_name) \u001b[39mas\u001b[39;00m lk:\n\u001b[1;32m     48\u001b[0m     \u001b[39m# share lock in case workers are already using `tqdm`\u001b[39;00m\n\u001b[1;32m     49\u001b[0m     \u001b[39mwith\u001b[39;00m PoolExecutor(max_workers\u001b[39m=\u001b[39mmax_workers, initializer\u001b[39m=\u001b[39mtqdm_class\u001b[39m.\u001b[39mset_lock,\n\u001b[1;32m     50\u001b[0m                       initargs\u001b[39m=\u001b[39m(lk,)) \u001b[39mas\u001b[39;00m ex:\n\u001b[0;32m---> 51\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(tqdm_class(ex\u001b[39m.\u001b[39mmap(fn, \u001b[39m*\u001b[39miterables, chunksize\u001b[39m=\u001b[39mchunksize), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/deepL_Q/lib/python3.11/site-packages/tqdm/notebook.py:254\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    253\u001b[0m     it \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m(tqdm_notebook, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__iter__\u001b[39m()\n\u001b[0;32m--> 254\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m it:\n\u001b[1;32m    255\u001b[0m         \u001b[39m# return super(tqdm...) will not catch exception\u001b[39;00m\n\u001b[1;32m    256\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m    257\u001b[0m \u001b[39m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/deepL_Q/lib/python3.11/site-packages/tqdm/std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1175\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   1177\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1178\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m   1179\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m   1180\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1181\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/deepL_Q/lib/python3.11/concurrent/futures/_base.py:619\u001b[0m, in \u001b[0;36mExecutor.map.<locals>.result_iterator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[39mwhile\u001b[39;00m fs:\n\u001b[1;32m    617\u001b[0m     \u001b[39m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[1;32m    618\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 619\u001b[0m         \u001b[39myield\u001b[39;00m _result_or_cancel(fs\u001b[39m.\u001b[39mpop())\n\u001b[1;32m    620\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    621\u001b[0m         \u001b[39myield\u001b[39;00m _result_or_cancel(fs\u001b[39m.\u001b[39mpop(), end_time \u001b[39m-\u001b[39m time\u001b[39m.\u001b[39mmonotonic())\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/deepL_Q/lib/python3.11/concurrent/futures/_base.py:317\u001b[0m, in \u001b[0;36m_result_or_cancel\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    316\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 317\u001b[0m         \u001b[39mreturn\u001b[39;00m fut\u001b[39m.\u001b[39mresult(timeout)\n\u001b[1;32m    318\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    319\u001b[0m         fut\u001b[39m.\u001b[39mcancel()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/deepL_Q/lib/python3.11/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m    449\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[0;32m--> 451\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_condition\u001b[39m.\u001b[39mwait(timeout)\n\u001b[1;32m    453\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    454\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/deepL_Q/lib/python3.11/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39macquire()\n\u001b[1;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionPipeline\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\n",
    "    \"runwayml/stable-diffusion-v1-5\",\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "pipe.to(\"cuda\")\n",
    "prompt = \"Piano by the sea\"\n",
    "pipe.enable_attention_slicing()\n",
    "image = pipe(prompt, num_inference_steps=50).images[0]\n",
    "\n",
    "image"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
