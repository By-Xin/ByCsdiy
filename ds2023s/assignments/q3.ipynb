{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import expit\n",
    "\n",
    "np.random.seed(123)\n",
    "n = 100000\n",
    "p = 100\n",
    "x = np.random.normal(size=(n, p))\n",
    "beta = np.random.normal(size=p)\n",
    "prob = expit(-0.5 + x.dot(beta))  # p = 1 / (1 + exp(-x * beta))\n",
    "y = np.random.binomial(1, prob, size=n)\n",
    "dat = np.hstack((y.reshape(n, 1), x))\n",
    "np.savetxt(\"logistic_data.txt\", dat, fmt=\"%.8f\", delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/04 15:15:22 WARN Utils: Your hostname, XinBys-MacBook-Air.local resolves to a loopback address: 127.0.0.1; using 10.65.116.79 instead (on interface en0)\n",
      "23/05/04 15:15:22 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/04 15:15:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "<pyspark.sql.session.SparkSession object at 0x7fd7288282b0>\n",
      "<SparkContext master=local[4] appName=PySpark RDD>\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init(\"/Users/xinby/Library/Spark\")\n",
    "from pyspark.sql import SparkSession\n",
    "# 本地模式\n",
    "spark = SparkSession.builder.\\\n",
    "    master(\"local[4]\").\\\n",
    "    appName(\"PySpark RDD\").\\\n",
    "    getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel(\"ERROR\")\n",
    "print(spark)\n",
    "print(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load softplus\n",
    "test = False\n",
    "def softplus(x):\n",
    "    # 此处插入代码\n",
    "    if (test): \n",
    "        print(f\"call func: softplus\")\n",
    "\n",
    "    ans = np.where(x>=0,np.log(1+np.exp(-x))+x,np.log(1+np.exp(x)))\n",
    "    \n",
    "    if (test): \n",
    "        print(f\"return.shape:{ans.shape}\")\n",
    "        print(f\"end func: softplus \\n\")\n",
    "        \n",
    "    return ans\n",
    "\n",
    "# load data to rdd\n",
    "def string_to_vector(line):\n",
    "    vector = line.split(\"\\t\")\n",
    "    return np.array(vector, dtype=float)\n",
    "\n",
    "def partition_to_matrix (iterator):\n",
    "    iterator_vec = map(string_to_vector, iterator)\n",
    "    data = list(iterator_vec)\n",
    "    if len(data) < 1:\n",
    "        matrix = np.array([])\n",
    "    else:\n",
    "        matrix = np.vstack(data)\n",
    "    yield matrix\n",
    "\n",
    "file = sc.textFile(\"logistic_data.txt\")\n",
    "\n",
    "data_partition = file.mapPartitions(partition_to_matrix)\n",
    "data_partition_nonempty = data_partition.filter(lambda x: x.shape[0] > 0)\n",
    "data_partition_nonempty.cache()\n",
    "data_partition_nonempty.count()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, objfn = 69314.71805599453, resid = 1.9999920000320117\n",
      "Iteration 5, objfn = 202.86044631969702, resid = 1.0015354523470537\n",
      "Iteration 10, objfn = 1.421137445056786, resid = 0.9342716889375833\n",
      "Iteration 15, objfn = 0.04573482357272951, resid = 0.31382220017651186\n",
      "Iteration 20, objfn = 0.015281002951894607, resid = 0.13255438286225463\n",
      "Iteration 25, objfn = 0.008887144886671194, resid = 0.08161794162574054\n",
      "Iteration 30, objfn = 0.006224562554280055, resid = 0.05859814575533662\n",
      "Iteration 35, objfn = 0.004778199880206557, resid = 0.04560299425169134\n",
      "Iteration 40, objfn = 0.0038729130125148004, resid = 0.03728511111661348\n",
      "Iteration 45, objfn = 0.0032540171446271415, resid = 0.03151467802325314\n",
      "Iteration 50, objfn = 0.0028046208910836867, resid = 0.027281077801450948\n",
      "Iteration 55, objfn = 0.0024636911177822185, resid = 0.024044526487084994\n",
      "Iteration 60, objfn = 0.0021962975438327703, resid = 0.021490968531090004\n",
      "Iteration 65, objfn = 0.00198102654280774, resid = 0.019425442055865716\n",
      "Iteration 70, objfn = 0.0018040285709730597, resid = 0.017720600902563888\n",
      "Iteration 75, objfn = 0.0016559532411974942, resid = 0.016289781041557205\n",
      "Iteration 80, objfn = 0.0015302617839552113, resid = 0.015071977998402986\n",
      "Iteration 85, objfn = 0.0014222457878076966, resid = 0.014023016771652408\n",
      "Iteration 90, objfn = 0.001328428922420244, resid = 0.013110128949037403\n",
      "Iteration 95, objfn = 0.0012461885745551626, resid = 0.01230849940088774\n",
      "Iteration 99, objfn = 0.001187362386190216, resid = 0.011734293629267256\n"
     ]
    }
   ],
   "source": [
    "# compute beta_hat fcn\n",
    "def compute_betahat(mat,beta_old):\n",
    "\n",
    "    if (test):\n",
    "        print(\"call fnc: comp_bhat\\n\")\n",
    "\n",
    "    y = mat[:,0].\n",
    "    if (test):\n",
    "        print(f\"0y{y.shape}\\n\")\n",
    "\n",
    "    x = mat\n",
    "    x[:,0]=1\n",
    "\n",
    "    if (test):\n",
    "        print(f\"0x{x.shape}\\n\")\n",
    "\n",
    "    xbeta = x.dot(beta_old)\n",
    "    if (test):\n",
    "        print(f\"1xb{xbeta.shape}\\n\")\n",
    "\n",
    "    prob = expit(xbeta) #这里的prob可以避免吗sigmoid（因为后面的objfn只用了softplus）？但是W该怎么算啊\n",
    "    if (test):\n",
    "        print(f\"2pr{prob.shape}\\n\")\n",
    "\n",
    "    w = prob * (1.0 - prob) + 1e-6\n",
    "    if (test):\n",
    "        print(f\"3w{w.shape}\\n\")\n",
    "\n",
    "    xtw = x.transpose() * w\n",
    "    if (test):\n",
    "        print(f\"4xtw{xtw.shape}\\n\")\n",
    "\n",
    "    xtwx = xtw.dot(x)\n",
    "    if (test): \n",
    "        print(f\"5xtwx{xtwx.shape}\\n\")\n",
    "\n",
    "    z = xbeta + (y - prob) / w\n",
    "    if (test): \n",
    "        print(f\"6z{z.shape}\\n\")\n",
    "\n",
    "    xtwz = xtw.dot(z)\n",
    "    if (test): \n",
    "        print(f\"7xtwz{xtwz.shape}\\n\")\n",
    "        print(f\"cal objfn = -np.sum(y*(x-softplus(x))+(y-1)*softplus(x))\")\n",
    "        print(f\"y*xbeta{(y*xbeta).shape}\")\n",
    "    \n",
    "    objfn = -np.sum( y * (xbeta-softplus(xbeta) ) + (y-1) * softplus(xbeta) )\n",
    "    \n",
    "    if (test): \n",
    "        print(f\"8objfn{objfn}\\n\")\n",
    "\n",
    "    if (test): \n",
    "        print(\"return from comp_beta\")\n",
    "\n",
    "    return xtwx, xtwz, objfn\n",
    "\n",
    "# iter computation\n",
    "\n",
    "p = data_partition_nonempty.first().shape[1]-1 #subtract y\n",
    "beta_hat = np.zeros(p+1)#initialization\n",
    "object_values = [] #init\n",
    "\n",
    "MaxIteration = 100 #iter settings\n",
    "epsilon = 1e-6 #iter settings\n",
    "\n",
    "for i in range(MaxIteration):\n",
    "    if (test):\n",
    "        print(f\"start iter:{i}\")\n",
    "    # 完整数据的 X'WX 和 X'Wz 是各分区的加和\n",
    "    xtwx, xtwz, objfn = data_partition_nonempty.\\\n",
    "        map(lambda part: compute_betahat(part, beta_hat)).\\\n",
    "        reduce(lambda x, y: (x[0] + y[0], x[1] + y[1], x[2] + y[2]))\n",
    "    # 计算新 beta\n",
    "    beta_new = np.linalg.solve(xtwx, xtwz)\n",
    "    if (test):\n",
    "        print(f\"bn{beta_new.shape}\")\n",
    "    # 计算 beta 的变化\n",
    "    resid = np.linalg.norm(beta_new - beta_hat)\n",
    "    if (np.mod(i,5)==0 or i==MaxIteration-1):\n",
    "        print(f\"Iteration {i}, objfn = {objfn}, resid = {resid}\")\n",
    "    object_values.append(objfn)\n",
    "    # 如果 beta 几乎不再变化，退出循环\n",
    "    if resid < epsilon:\n",
    "        print(f\"Iteration {i}, objfn = {objfn}, resid = {resid}\")\n",
    "        break\n",
    "    # 更新 beta\n",
    "    beta_hat = beta_new\n",
    "\n",
    "    ############Q: 这里是说要自己推一个Gradient的递推公式？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.82606808e+01 -6.42966967e-15  2.50757163e-16 -1.13096510e-14\n",
      "  1.13611481e-14  8.79546633e-15 -1.36304139e-14 -1.31772968e-14\n",
      " -6.26401961e-19 -2.90420119e-15 -7.51085147e-17 -3.31720583e-15\n",
      " -8.93853355e-17 -9.87538988e-15  7.94735760e-15 -4.36984040e-15\n",
      " -1.61157090e-14 -2.02442529e-15  1.03671228e-14 -4.12070588e-15\n",
      "  2.24014708e-14 -1.08807404e-14 -4.47106877e-15  1.91860400e-14\n",
      "  1.01117976e-14 -1.20879950e-14  6.71999571e-15 -1.08185291e-14\n",
      " -1.20263466e-16  1.38023847e-15 -7.32651923e-15  1.26341588e-14\n",
      "  6.23554394e-15 -1.78793313e-14 -6.93090602e-15  8.10153345e-15\n",
      "  2.67888769e-14  1.22746367e-14  2.02740305e-14 -4.31849411e-16\n",
      "  1.23355130e-16  1.49628461e-14  4.04542951e-16 -1.28348703e-14\n",
      " -2.16672095e-17  8.52851970e-15  4.75046170e-15  5.40555375e-15\n",
      " -1.38173165e-14  1.58867995e-15  1.42244199e-14 -1.80736878e-14\n",
      "  2.64692890e-16 -1.11307536e-14 -1.06756611e-16  1.14124746e-15\n",
      " -1.35398306e-14 -8.28340179e-15 -3.44426206e-15 -2.53127386e-14\n",
      "  2.44055200e-16 -1.30679140e-14  5.70257934e-16 -2.46550075e-15\n",
      " -1.77239328e-14 -1.30458405e-15 -1.02998657e-14  1.50460656e-14\n",
      "  1.62233216e-14 -6.31348416e-15 -1.67293989e-14 -7.41779733e-15\n",
      " -2.63678842e-15 -1.62288241e-15 -1.53577869e-14 -2.31573102e-14\n",
      " -6.96220305e-15 -3.97460044e-15 -4.36439475e-15 -8.99628690e-15\n",
      " -1.17707615e-16 -1.41509334e-16 -2.18657710e-14 -1.06885581e-14\n",
      "  2.54274191e-14 -1.07886936e-14 -2.13068935e-14 -1.67075882e-14\n",
      " -1.76660928e-16  2.45747080e-14  2.60807415e-16  1.63296705e-15\n",
      "  7.90139761e-17 -2.94804543e-15  1.53123499e-14  6.12884126e-15\n",
      " -2.95872845e-16 -9.13874250e-15  8.57032353e-15  1.52129610e-14\n",
      " -3.48577362e-16]\n",
      "[0.99999999 0.99999999 0.99999999 ... 0.99999999 0.99999999 0.99999999]\n"
     ]
    }
   ],
   "source": [
    "x = dat\n",
    "x[:,0] = 1\n",
    "print(beta_hat)\n",
    "xbetahat = x.dot(beta_hat)\n",
    "probhat = expit(xbetahat)\n",
    "print(probhat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
